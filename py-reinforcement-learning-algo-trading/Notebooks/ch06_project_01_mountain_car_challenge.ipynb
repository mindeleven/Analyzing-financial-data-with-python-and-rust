{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fa1b1d9",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Project 1: The Mountain Car Challenge "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb1f261",
   "metadata": {},
   "source": [
    "*[Coding along with [Reinforcement Learning for Algorithmic Trading with Python](https://www.udemy.com/course/reinforcement-learning-for-algorithmic-trading-with-python/), an Udemy online course by Alexander Hagmann]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a738c-1302-40a7-a103-4d5939770ebd",
   "metadata": {},
   "source": [
    "### One random Episode - with human rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f3cb3-2edb-414e-862b-892efefa4afd",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ I have installed Anaconda and all required libraries to work with OpenAI´s gymnasium Reinforcement Learning environments. Also I have installed Microsoft Visual Studio to visualize environments such as Mountain Car. Please provide a Python code example that creates and runs a random episode in the 'MountainCar-v0' environment using the gymnasium library, with human rendering enabled and printing the total reward and number of steps at the end. Please note that gym is now gymnasium.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2592b3-7ac5-40c0-bd06-a55a590c66a8",
   "metadata": {},
   "source": [
    "Great! Here’s a Python code example that creates and runs a random episode in the **'MountainCar-v0'** environment using the **gymnasium** library, with **human rendering** enabled and printing the **total reward** and **number of steps** at the end:\n",
    "\n",
    "```python\n",
    "import gymnasium as gym\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n",
    "\n",
    "# Initialize the environment\n",
    "observation, info = env.reset()\n",
    "\n",
    "total_reward = 0\n",
    "num_steps = 0\n",
    "done = False\n",
    "\n",
    "# Run a random episode\n",
    "while not done:\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Perform the action in the environment\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # Accumulate the reward and count the steps\n",
    "    total_reward += reward\n",
    "    num_steps += 1\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total Reward: {total_reward}\")\n",
    "print(f\"Total Steps: {num_steps}\")\n",
    "\n",
    "# Close the environment\n",
    "env.close()\n",
    "```\n",
    "\n",
    "### Explanation of the Code:\n",
    "1. **`gymnasium.make(\"MountainCar-v0\", render_mode=\"human\")`**: \n",
    "   - Initializes the **MountainCar-v0** environment with rendering enabled so you can visually observe the car’s movement.\n",
    "\n",
    "2. **`env.reset()`**:\n",
    "   - Resets the environment to its initial state and returns the initial observation and environment info.\n",
    "\n",
    "3. **`env.action_space.sample()`**:\n",
    "   - Randomly samples an action from the action space (which, for **MountainCar**, can be one of three discrete actions: push left, no push, or push right).\n",
    "\n",
    "4. **`env.step(action)`**:\n",
    "   - Takes the sampled action and returns the next observation, reward, whether the episode is done, and any additional info. The loop continues until `done` is `True` (when the car reaches the flag or max steps are taken).\n",
    "\n",
    "5. **`total_reward` and `num_steps`**:\n",
    "   - These accumulate the reward over the episode and count the number of steps, respectively.\n",
    "\n",
    "6. **`env.close()`**:\n",
    "   - Closes the environment to stop the rendering window after the episode finishes.\n",
    "\n",
    "### Libraries and Setup:\n",
    "- **gymnasium**: The new version of the Gym library for RL environments.\n",
    "- **render_mode='human'**: Ensures the environment window is shown for human interaction.\n",
    "  \n",
    "This code will run a random agent in the **MountainCar** environment, render the environment visually, and display the total reward and number of steps after the episode ends.\n",
    "\n",
    "Let me know if you encounter any issues or need further customizations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d284051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward: -8085.0\n",
      "Total Steps: 8085\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"MountainCar-v0\", render_mode=\"human\")\n",
    "\n",
    "# Initialize the environment\n",
    "observation, info = env.reset()\n",
    "\n",
    "total_reward = 0\n",
    "num_steps = 0\n",
    "done = False\n",
    "\n",
    "# Run a random episode\n",
    "while not done:\n",
    "    # Take a random action\n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    # Perform the action in the environment\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    \n",
    "    # Accumulate the reward and count the steps\n",
    "    total_reward += reward\n",
    "    num_steps += 1\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total Reward: {total_reward}\")\n",
    "print(f\"Total Steps: {num_steps}\")\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee7db5-d2d3-488b-a828-c0779c6a0f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c26e32-c852-438b-85d2-8f21e8d83180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e126c-5f4b-476d-9d40-2c698f7e1fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b842bc42-f379-469a-9733-ce6c9f1aa192",
   "metadata": {},
   "source": [
    "### Multiple random Episodes - with human rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb2dcb-a9d5-4cc9-b9c4-c2c80081a5f0",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ Now, I want to run multiple random episodes with human rendering. Please adjust the code accordingly with as few changes as possible.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82a333-5646-4358-bc5a-0bf7c6e3a60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9995fd6f-6f2e-454b-a8f9-ac9da12eb8ad",
   "metadata": {},
   "source": [
    "### Performance Evaluation / Success Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8707f1eb-cfa2-472d-be54-0e3ce2f51241",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ Now, I want to run multiple random episodes with human rendering. Please adjust the code accordingly with as few changes as possible.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218ae7f-bb91-4fa9-9428-b747b9cea473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faae01c8-8cd3-4021-8d4a-d8c084d5fb63",
   "metadata": {},
   "source": [
    "### Performance Evaluation / Success Measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465b5d3-43a5-4d37-a3c0-011fcf1c000f",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ Now, let´s focus on Performance Measurement and Evaluation. I want to measure the performance / success of the random agent and print the performance at the end of the random run. Please make an appopriate proposal with various metrics. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d399270-24f1-4a75-b698-345f968a00b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b610490-eb95-4f30-88d7-ffc20ac53f16",
   "metadata": {},
   "source": [
    "### RGB Rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1d645-b431-4793-88a3-02d27995ace4",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ Human rendering is really slow. Please remove human rendering to run many episodes in no time. Print every 100th episode only.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f40ce9-cae5-4c65-a76a-7889cad1e6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "674ea282-0d21-4069-94c3-69002be867fa",
   "metadata": {},
   "source": [
    "### Training an RL Agent with Q-Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce59cfcc-2f87-4473-be82-b3be99d06d20",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ I have the following code to run multiple random episodes of OpenAI´s MountainCar challenge: ---insert code---</span>\n",
    ">\n",
    "> <span style=\"color:blue\">Now, I want to create and train a Reinforcement Learning Agent that can reach the target with as few steps as possible and with a high success rate. Please build on the existing code and train the Agent. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a0e6de-5c19-4c63-9586-0bef0d8868f4",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ XXX</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8b8ee-4773-4eb9-8566-2e9cdcbfd3a7",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ XXX</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36717cd5-16fc-4ab3-9bcb-3dad80433648",
   "metadata": {},
   "source": [
    "> <span style=\"color:blue\">__Prompt:__ XXX</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
