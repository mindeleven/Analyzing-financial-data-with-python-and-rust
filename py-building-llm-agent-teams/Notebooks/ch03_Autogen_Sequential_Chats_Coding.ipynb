{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7dd28e-c071-481e-bda8-23f6dfadb16a",
   "metadata": {},
   "source": [
    "## Autogen Sequential Chats Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e6c43-8223-47d0-8d51-3e40ae66a24c",
   "metadata": {},
   "source": [
    "*[Coding along with the Udemy online course AI Agents: Building Teams of LLM Agents that Work For You by Mohsen Hassan & Ilyass Tabiai]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3be3ef-bb0a-4bb9-9dd1-adb37fc2f782",
   "metadata": {},
   "source": [
    "Agents can be used to onboard users into a live chat system to solve issues like you can see it on banking webiste or phone provider webistes.\n",
    "\n",
    "For this example of a sequential chat we will assume that these agents are deployed by a phone provider company called \"ACME\". The agents are used to gather specifc information about a user that needs help, then to pass that information to a human that will directly have a clear understanding of who requires help, where they're from and what their problem is. The human should be able to immediately act on this information and help the user.\n",
    "\n",
    "The accomplish this task 3 agents are needed:\n",
    "\n",
    "An __Onboarding Personal Information Agent__ whose goal it is to get the name and location of the customer.\n",
    "\n",
    "An __Onboarding Issue Agent__ whose it is goal to determine what the issue of the customer is.\n",
    "\n",
    "A __Customer Engagement Agent__ who will interact with the customer until a human agent is available for the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd1cc8c-8d78-4080-a5f9-daff5d38ad8e",
   "metadata": {},
   "source": [
    "An autogen example for Solving Multiple Tasks in a Sequence of Chats can be found at the __[Autogen Docs](https://microsoft.github.io/autogen/docs/notebooks/agentchat_multi_task_chats/)__: The notebook there \"showcases how to use the new chat interface of conversational agents in AutoGen: initiate_chats, to conduct a series of tasks. This new interface allows one to pass multiple tasks and their corresponding dedicated agents. Once initiate_chats is invoked, the tasks will be solved sequentially, with the summaries from previous tasks provided to subsequent tasks as context, if the summary_method argument is specified.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5808b0cd-0735-4d84-a2ae-ccd3c5278562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9f04df8-aa48-4d70-ae15-1da79e22cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and send your api key to GitHub!\n"
     ]
    }
   ],
   "source": [
    "api_key = pd.read_csv(\"~/tmp/chat_gpt/autogen_agent_1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and send your api key to GitHub!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3843a4e5-241e-41a2-87ab-b424e243f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and send your api key to GitHub!\n"
     ]
    }
   ],
   "source": [
    "# creating a Conversable Agent to accomlpish a simple task\n",
    "# 1st thing to do is to create a LLM config that specifies which LLM we want to use\n",
    "# model from the list of models provided by OpenAI https://platform.openai.com/docs/models/continuous-model-upgrades\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    # \"model\": \"gpt-3.5-turbo\",\n",
    "    \"api_key\": api_key\n",
    "    }\n",
    "print(\"Don't be a fool and send your api key to GitHub!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6459c5-bc0a-4c1d-9e6a-bb11f60c7598",
   "metadata": {},
   "source": [
    "### Agents definition: (1) Onboarding Personal Information Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e4746-0e8d-4b6d-83cf-c103aecd9493",
   "metadata": {},
   "source": [
    "The main goal of the Onboarding Personal Information Agent is to get the name and location of the customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13c40dfa-808c-45b0-835e-2b6b1a44c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 10-01 10:52:55] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Personal_Information_Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you work for a phone provider called ACME.\n",
    "    Your job is to gather the customer's name and location.\n",
    "    Do not ask for any other information, only ask about the customer's name and location.\n",
    "    After the customer gives you their name and location, repeat them \n",
    "    and thank the user, and ask the user to answer with TERMINATE to move on to describing their issue.\n",
    "    ''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18e8a5-d914-4c28-9993-742a26ea34f2",
   "metadata": {},
   "source": [
    "### Agents definition: (2) Onboarding Issue Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d959e6a-d52a-4599-9d82-2dd3e92432cf",
   "metadata": {},
   "source": [
    "The main goal of the Onboarding Issue Agent is to determine the issue the customer is facing with ACME's products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e138580-5bd4-4df3-89cf-2aa176d2a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 09-30 09:52:15] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_issue_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Issue_Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you work for a phone provider called ACME,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather the product the customer use and the issue they currently \n",
    "    have with the product,\n",
    "    Do not ask for other information.\n",
    "    After the customer describes their issue, repeat it and add\n",
    "    \"Please answer with 'TERMINATE' if I have correctly understood your issue.\" ''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059da1d7-c7c4-4e21-804b-2ab1e2846259",
   "metadata": {},
   "source": [
    "### Agents definition: (3) Customer Engagement Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a7f00-b486-4bf2-add5-06628d4331a6",
   "metadata": {},
   "source": [
    "The main goal of the **Customer Engagement Agent** is to interact with the customer based on the previously gathered information until a human agent is available to solve the customer's issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2830626-c63d-4ccb-826c-d360442c85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 10-01 10:58:03] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer_Engagement_Agent\",\n",
    "    system_message='''You are a helpful customer service agent.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    You are here to provide fun and useful information to the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b609f05-41e1-4357-934e-9de58566200e",
   "metadata": {},
   "source": [
    "### Customer Proxy Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99174d5a-405a-4694-a538-2b17902c8580",
   "metadata": {},
   "source": [
    "The Customer Proxy Agent is a Conversable Agent that allows the human to play the role of the agent. It's not an LLM therefore `llm_config=False` and it has `human_input_mode=\"ALWAYS\"` which means that you, the human, will be the customer through this agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de9e8d72-6fba-4f5c-a81f-55f34be3ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220c568-1a46-4620-89d8-31bdb82e0879",
   "metadata": {},
   "source": [
    "### Next Step: Chat orchestration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aef420-f9df-468b-aad4-d6020a548ec9",
   "metadata": {},
   "source": [
    "Orchastrating how the chat will happen means that we will define in which order agents will interact and who'll interact with who when. To define this, we will use a list, that will contain several elements, each one corresponding to a chat. The chats will then happen in that specific order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2be8639-88b3-4efe-b70f-ad4f0ec17185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a `chat` object\n",
    "chats = [] # This is going to be our list of chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cc17a-16c4-453d-b8f1-a0ba56a7180e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
