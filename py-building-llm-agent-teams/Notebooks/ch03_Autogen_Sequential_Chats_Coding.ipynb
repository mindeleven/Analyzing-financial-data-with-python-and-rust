{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7dd28e-c071-481e-bda8-23f6dfadb16a",
   "metadata": {},
   "source": [
    "## Autogen Sequential Chats Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e6c43-8223-47d0-8d51-3e40ae66a24c",
   "metadata": {},
   "source": [
    "*[Coding along with the Udemy online course AI Agents: Building Teams of LLM Agents that Work For You by Mohsen Hassan & Ilyass Tabiai]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3be3ef-bb0a-4bb9-9dd1-adb37fc2f782",
   "metadata": {},
   "source": [
    "Agents can be used to onboard users into a live chat system to solve issues like you can see it on banking webiste or phone provider webistes.\n",
    "\n",
    "For this example of a sequential chat we will assume that these agents are deployed by a phone provider company called \"ACME\". The agents are used to gather specifc information about a user that needs help, then to pass that information to a human that will directly have a clear understanding of who requires help, where they're from and what their problem is. The human should be able to immediately act on this information and help the user.\n",
    "\n",
    "The accomplish this task 3 agents are needed:\n",
    "\n",
    "An __Onboarding Personal Information Agent__ whose goal it is to get the name and location of the customer.\n",
    "\n",
    "An __Onboarding Issue Agent__ whose it is goal to determine what the issue of the customer is.\n",
    "\n",
    "A __Customer Engagement Agent__ who will interact with the customer until a human agent is available for the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd1cc8c-8d78-4080-a5f9-daff5d38ad8e",
   "metadata": {},
   "source": [
    "An autogen example for Solving Multiple Tasks in a Sequence of Chats can be found at the __[Autogen Docs](https://microsoft.github.io/autogen/docs/notebooks/agentchat_multi_task_chats/)__: The notebook there \"showcases how to use the new chat interface of conversational agents in AutoGen: initiate_chats, to conduct a series of tasks. This new interface allows one to pass multiple tasks and their corresponding dedicated agents. Once initiate_chats is invoked, the tasks will be solved sequentially, with the summaries from previous tasks provided to subsequent tasks as context, if the summary_method argument is specified.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5808b0cd-0735-4d84-a2ae-ccd3c5278562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9f04df8-aa48-4d70-ae15-1da79e22cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and send your api key to GitHub!\n"
     ]
    }
   ],
   "source": [
    "api_key = pd.read_csv(\"~/tmp/chat_gpt/autogen_agent_1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and send your api key to GitHub!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3843a4e5-241e-41a2-87ab-b424e243f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and send your api key to GitHub!\n"
     ]
    }
   ],
   "source": [
    "# creating a Conversable Agent to accomlpish a simple task\n",
    "# 1st thing to do is to create a LLM config that specifies which LLM we want to use\n",
    "# model from the list of models provided by OpenAI https://platform.openai.com/docs/models/continuous-model-upgrades\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    # \"model\": \"gpt-3.5-turbo\",\n",
    "    \"api_key\": api_key\n",
    "    }\n",
    "print(\"Don't be a fool and send your api key to GitHub!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6459c5-bc0a-4c1d-9e6a-bb11f60c7598",
   "metadata": {},
   "source": [
    "### Agents definition: (1) Onboarding Personal Information Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e4746-0e8d-4b6d-83cf-c103aecd9493",
   "metadata": {},
   "source": [
    "The main goal of the Onboarding Personal Information Agent is to get the name and location of the customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13c40dfa-808c-45b0-835e-2b6b1a44c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 10-01 10:52:55] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Personal_Information_Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you work for a phone provider called ACME.\n",
    "    Your job is to gather the customer's name and location.\n",
    "    Do not ask for any other information, only ask about the customer's name and location.\n",
    "    After the customer gives you their name and location, repeat them \n",
    "    and thank the user, and ask the user to answer with TERMINATE to move on to describing their issue.\n",
    "    ''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18e8a5-d914-4c28-9993-742a26ea34f2",
   "metadata": {},
   "source": [
    "### Agents definition: (2) Onboarding Issue Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d959e6a-d52a-4599-9d82-2dd3e92432cf",
   "metadata": {},
   "source": [
    "The main goal of the Onboarding Issue Agent is to determine the issue the customer is facing with ACME's products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e138580-5bd4-4df3-89cf-2aa176d2a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 09-30 09:52:15] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_issue_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Issue_Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you work for a phone provider called ACME,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather the product the customer use and the issue they currently \n",
    "    have with the product,\n",
    "    Do not ask for other information.\n",
    "    After the customer describes their issue, repeat it and add\n",
    "    \"Please answer with 'TERMINATE' if I have correctly understood your issue.\" ''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059da1d7-c7c4-4e21-804b-2ab1e2846259",
   "metadata": {},
   "source": [
    "### Agents definition: (3) Customer Engagement Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a7f00-b486-4bf2-add5-06628d4331a6",
   "metadata": {},
   "source": [
    "The main goal of the **Customer Engagement Agent** is to interact with the customer based on the previously gathered information until a human agent is available to solve the customer's issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2830626-c63d-4ccb-826c-d360442c85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 10-01 10:58:03] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer_Engagement_Agent\",\n",
    "    system_message='''You are a helpful customer service agent.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    You are here to provide fun and useful information to the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b609f05-41e1-4357-934e-9de58566200e",
   "metadata": {},
   "source": [
    "### Agents definition: (4) Customer Proxy Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99174d5a-405a-4694-a538-2b17902c8580",
   "metadata": {},
   "source": [
    "The question now is how to get the user into this conversation to engage with the agents. The achieve this we define a fourth agent, the Customer Proxy Agent.\n",
    "\n",
    "The __Customer Proxy Agent__ is a Conversable Agent that allows the human (the user, which is you or us) to play the role of the agent. It's not an LLM therefore `llm_config=False` and it has `human_input_mode=\"ALWAYS\"` which means that you, the human, will be the customer through this agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de9e8d72-6fba-4f5c-a81f-55f34be3ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False, # NO llm config or model here; can't interact with llm\n",
    "    code_execution_config=False, # code execution would be possible but we don't want it here\n",
    "    human_input_mode=\"ALWAYS\", # NO llm but ALWAYS human input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220c568-1a46-4620-89d8-31bdb82e0879",
   "metadata": {},
   "source": [
    "### Next Step: Chat orchestration - Creating the Chat Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aef420-f9df-468b-aad4-d6020a548ec9",
   "metadata": {},
   "source": [
    "Orchastrating how the chat will happen means that we will define in which order agents will interact and who'll interact with who when. To define this, we will use a list, that will contain several elements, each one corresponding to a chat. The chats will then happen in that specific order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2be8639-88b3-4efe-b70f-ad4f0ec17185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a `chat` object\n",
    "chats = [] # This is going to be our list of chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb9ead-3bb9-4e33-96dc-8af321ddf572",
   "metadata": {},
   "source": [
    "### Chat orchestration (1): Onboarding Agent with Customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3992a5-05e5-450c-a8be-e9bd5fb8f6c0",
   "metadata": {},
   "source": [
    "We will now define the first chat and add it to this list. \n",
    "\n",
    "The first chat will be between our first agent, the **Onboarding Personal Information Agent** and the **customer**, who is going to be us.\n",
    "\n",
    "The first message will be sent by the **Onboarding Personal Information Agent** and will be:\n",
    "> *Hello, I'm here to help you get started with our product. \n",
    "            Could you tell me your name?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d7579-468e-4021-8f69-a378bdccdddb",
   "metadata": {},
   "source": [
    "__Carrying data to the next chat:__\n",
    "\n",
    "__Specify the summary format:__ In order to make the transition easier with the next agent, we are going to ask for a slightly different type of summary than we did before with this agent. We are going to request a summary generated by the LLM, but **we will specify that the summary should return the name and location of the customer in a JSON format:** `{'name': '', 'location': ''}`. This is a structured data format that can be easily read by another agent but **also by another app or protocol**. This shows how an LLM agent can be used to interact with other apps.\n",
    "\n",
    "__The clear_history paramter:__ Since we only want to transfer name and location to the next chat and we specifically specified how we want to transfer this data, we are going to add a new parameter, the `clear_history` to `True` which means that no data other than the one specified in the summary will be sent to the next chat. If we set it to `False` the agent from the next chat will be aware about the previous exchange with the user. We'll use that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ce5a5b9-a9c2-4c5b-a823-a6e798602120",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats.append(\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Hello, I'm here to help you solve any issue you have with our products. \"\n",
    "            \"Could you tell me your name?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "        \"summary_prompt\" : \"Return the customer information \"\n",
    "                             \"into a JSON object only: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"clear_history\" : True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1712f38c-a338-4cf6-a773-db23293281c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sender': <autogen.agentchat.conversable_agent.ConversableAgent at 0x130985bb0>,\n",
       "  'recipient': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1308ffc20>,\n",
       "  'message': \"Hello, I'm here to help you solve any issue you have with our products. Could you tell me your name?\",\n",
       "  'summary_method': 'reflection_with_llm',\n",
       "  'summary_args': {'summary_prompt': \"Return the customer information into a JSON object only: {'name': '', 'location': ''}\"},\n",
       "  'clear_history': True}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056a59fb-a26b-41e1-b3a4-6d95e96af3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
