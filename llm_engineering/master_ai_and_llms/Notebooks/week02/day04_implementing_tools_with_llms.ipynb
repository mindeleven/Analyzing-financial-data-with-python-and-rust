{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfaec8d3-0780-43e0-8358-43aaca7a5fe1",
   "metadata": {},
   "source": [
    "## Implementing Tools with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36033d90-fdaa-4328-a7f3-f7c3616fd7a3",
   "metadata": {},
   "source": [
    "*[Coding along with the Udemy online course [LLM Engineering: Master AI & Large Language Models](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/) by Ed Donner; GitHub repo can be found at [github.com/ed-donner/llm_engineering](https://github.com/ed-donner/llm_engineering)]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c9113-5e75-4ac5-9aa0-6652e4aaebba",
   "metadata": {},
   "source": [
    "## Tools Project: Airline AI Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c003bd1a-7623-4a7f-a2d4-fb87273cf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "from pprint import pprint\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76616cab-a9e1-456e-8d30-dd2839184d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and sent your api key to github\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = pd.read_csv(\"~/tmp/chat_gpt/agentic-design-1.txt\", sep=\" \", header=None)[0][0]\n",
    "\n",
    "# connect to openai\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "print(\"Don't be a fool and sent your api key to github\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b890d7-18dc-4c71-ba56-4c87b89140b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a helpful assistant for an Airline called FlightAI. Give short, courteous answers, no more than 1 sentence. Always be accurate. If you don't know the answer, say so.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\"\n",
    "system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f55227d2-f0fd-4952-ade0-0335f59ad18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat function in the style gradio expects it\n",
    "# NO streaming back results this time\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for human, assistant in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": human})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32916cc3-3eb6-4fd4-9d66-1ac1e8b58d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juergenkober/Library/Caches/pypoetry/virtualenvs/llm-engineering-E34XR2a1-py3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brief check of gradio\n",
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717a808-60e9-4e84-9e49-292f6458132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, What are Tools?\n",
    "\n",
    "Tools are an incredibly powerful feature provided by the frontier LLMs.\n",
    "\n",
    "With tools, you can write a function, and have the LLM call that function as part of its response.\n",
    "\n",
    "Sounds almost spooky.. we're giving it the power to run code on our machine?\n",
    "\n",
    "Well, kinda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b8699-10dd-4844-9837-a36882a28748",
   "metadata": {},
   "source": [
    "Asking Claude.ai, \n",
    "\n",
    "> <span style=\"color:green\">__What are tools in AI calls via an API?__</span>\n",
    "\n",
    "Tools in AI APIs are external functions or capabilities that AI models can use to perform specific tasks. Think of them like specialized add-ons that expand what the AI can do beyond just processing text.\n",
    "\n",
    "Let me explain with some common examples:\n",
    "\n",
    "1. Code Interpreter\n",
    "- Allows the AI to execute and run code\n",
    "- Useful for data analysis, calculations, and generating visualizations\n",
    "\n",
    "2. Web Browsing\n",
    "- Enables the AI to search and retrieve current information from the internet\n",
    "- Can help provide up-to-date facts and references\n",
    "\n",
    "3. File Handling\n",
    "- Lets the AI read, write, and manipulate different file types\n",
    "- Examples: reading PDFs, analyzing spreadsheets, processing images\n",
    "\n",
    "4. API Integration\n",
    "- Allows the AI to interact with other services\n",
    "- For example: checking weather data, sending emails, or accessing databases\n",
    "\n",
    "When making API calls with tools:\n",
    "- The developer specifies which tools the AI can access\n",
    "- Each tool has defined inputs and outputs\n",
    "- The AI determines when to use specific tools based on the task\n",
    "- Results from tools can be incorporated into the AI's responses\n",
    "\n",
    "Would you like me to elaborate on any specific aspect of AI tools or how they're implemented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98fd8c9f-a693-415a-a738-35a51a451330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for tokyo\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$1400'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's start by making a useful function\n",
    "\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "# get the ticket price for a given city\n",
    "def get_ticket_price(destination_city):\n",
    "    # starting with print statement to see later when this function is called\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")\n",
    "\n",
    "get_ticket_price(\"tokyo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbbc5c-65c0-4790-a2fc-ed7926b521ed",
   "metadata": {},
   "source": [
    "Asking Claude.ai once again, \n",
    "\n",
    "> <span style=\"color:green\">__There's a particular dictionary structure that's required to describe a function that can be used as a tool. Can you give me an example of this dictionary structure and describe it?__</span>\n",
    "\n",
    "The tool/function definition in LLM API calls typically follows a JSON-like dictionary structure that describes the function's properties. Here's an example:\n",
    "\n",
    "```python\n",
    "tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"description\": \"Get the current price of a stock by its ticker symbol\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"symbol\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The stock ticker symbol (e.g., AAPL, GOOGL)\"\n",
    "                },\n",
    "                \"currency\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"USD\", \"EUR\", \"GBP\"],\n",
    "                    \"description\": \"The currency for the stock price\",\n",
    "                    \"default\": \"USD\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"symbol\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's break down the key components:\n",
    "\n",
    "1. Top Level:\n",
    "   - `type`: Specifies this is a function tool\n",
    "   - `function`: Contains the function's specifications\n",
    "\n",
    "2. Function Properties:\n",
    "   - `name`: The function identifier\n",
    "   - `description`: Explains what the function does\n",
    "   - `parameters`: Defines the input schema\n",
    "\n",
    "3. Parameters Structure:\n",
    "   - `type`: Usually \"object\" for the parameters container\n",
    "   - `properties`: Defines each parameter:\n",
    "     - Data type (string, number, boolean, etc.)\n",
    "     - Description\n",
    "     - Optional constraints (enum, min/max, pattern, etc.)\n",
    "     - Default values\n",
    "   - `required`: List of mandatory parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aca619b5-b518-46d4-b8d4-555e5ae28705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "# description in plain ol' english so the llm understands when to call this function\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefdc50d-3c04-4c6a-82d9-4e7bdc4d4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# including the function (which is one tool) in a list of tools:\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b76a08-97b1-4a22-ae05-1325d14483ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'get_ticket_price',\n",
       "   'description': \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'destination_city': {'type': 'string',\n",
       "      'description': 'The city that the customer wants to travel to'}},\n",
       "    'required': ['destination_city'],\n",
       "    'additionalProperties': False}}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c2a027-ef5e-4d20-91cc-fed61d2135d6",
   "metadata": {},
   "source": [
    "#### __Giving an LLM the Power to Use our Tool__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f007798-2a93-4f1c-86ca-75651d4ba5d9",
   "metadata": {},
   "source": [
    "What we actually going to do here is giving the LLM the opportunity to inform us that it wants us to run the tool we're providing. We're going to rewrite the `chat` function to allow OpenAI \"to call our tool\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51adc389-3aef-48c5-b643-6a50aa3ecb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the handle_tool_call function that we're going to use in the following chat() function\n",
    "# go through the chat function first to understand the why and what\n",
    "# parameter: message from gpt-4o\n",
    "def handle_tool_call(message):\n",
    "    # first we need to unpack the message to find out which tools we need to call\n",
    "    tool_call = message.tool_calls[0]\n",
    "    # second we need to extract the arguments from the tool call and extract them\n",
    "    arguments = json.loads(tool_call.function.arguments) # gets returned into the form of json\n",
    "    city = arguments.get('destination_city') # looking for parameters in arguments dictionary\n",
    "    price = get_ticket_price(city) # calling our very own simple function\n",
    "    # building the response\n",
    "    response = {\n",
    "        \"role\": \"tool\", # a new role here: tool\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}), # dict turned into a string\n",
    "        \"tool_call_id\": message.tool_calls[0].id\n",
    "    }\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e07e4af1-95fd-4f38-ab8a-fadf3f0fbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for human, assistant in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": human})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    # now calling chat.completions.create with tools as a parameter\n",
    "    # the llm is informed by the description that this is a function it cal call\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    # what are we checking for here?\n",
    "    # the llm is sending a response back and will include 'finish_reason' into it\n",
    "    # it means to tell us, that it doesn't know the answer yet and wants us to call one of the available tools\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message # getting the message that requests to run a tool\n",
    "        # next: unpack the message, figure out what it wants to do and do it\n",
    "        # handle_tool_call() will unpack the message from gpt and call our tool\n",
    "        response, city = handle_tool_call(message)\n",
    "        # next: adding two more rows to our list of messages \n",
    "        messages.append(message) # 1st: the message that we got back from gpt-4o\n",
    "        messages.append(response) # 2nd: our result of calling the function\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages) # sending it all back to llm\n",
    "        # we don't send in tools a second time because we don't expect that it will needed\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d277125a-4bc9-471b-9d65-9bf8bc956ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juergenkober/Library/Caches/pypoetry/virtualenvs/llm-engineering-E34XR2a1-py3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for London\n",
      "Tool get_ticket_price called for Paris\n",
      "Tool get_ticket_price called for Tokyo\n",
      "Tool get_ticket_price called for Berlin\n",
      "Tool get_ticket_price called for Tangier\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa19ef-1220-4d99-ab91-d5de184f97d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
