{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc10942-98d3-44e2-94a8-86cb757572f6",
   "metadata": {},
   "source": [
    "## Build a Conversational AI Chatbot with OpenAI and Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91423ec-df23-467b-95b2-cdb302e43045",
   "metadata": {},
   "source": [
    "*[Coding along with the Udemy online course [LLM Engineering: Master AI & Large Language Models](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/) by Ed Donner; GitHub repo can be found at [github.com/ed-donner/llm_engineering](https://github.com/ed-donner/llm_engineering)]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5deb263e-cb63-4f1c-b495-777112de43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "# and finally, let's import gradio as a new feature here\n",
    "# https://www.gradio.app/guides/quickstart\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef68cefd-82b0-4abd-bcd4-3b66c5ae51cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and sent your api key to github\n",
      "Don't be a fool and sent your api key to github\n",
      "Don't be a fool and sent your api key to github\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = pd.read_csv(\"~/tmp/chat_gpt/agentic-design-1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and sent your api key to github\")\n",
    "\n",
    "anthropic_api_key = pd.read_csv(\"~/tmp/anthropic/anthropic-key-1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and sent your api key to github\")\n",
    "\n",
    "google_api_key = pd.read_csv(\"~/tmp/google-gemini/gemini-key-1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and sent your api key to github\")\n",
    "\n",
    "# connect to openai\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# connect to anthropic\n",
    "claude = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "\n",
    "# connect to gemini\n",
    "google.generativeai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52cd133a-3982-4640-ad77-f90316237b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENAI MODEL\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb726b9-4eae-45a7-aaa0-2a383a796ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You're a helpful assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd8ea94-6bd6-4568-ba9a-9d23a83dd237",
   "metadata": {},
   "source": [
    "__As a reminder:__ For a simple conversation between user and system prompts are organized into lists like this:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user prompt here\"}\n",
    "]\n",
    "```\n",
    "\n",
    "This structure can also be used to reflect a longer conversation history with different roles:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "The advantage of this approach is that we can use it to engage in a longer interaction with history. \n",
    "\n",
    "We will write a function `chat(message, history)` where:\n",
    "**message** is the prompt to use\n",
    "**history** is a list of pairs of user message with assistant's reply\n",
    "\n",
    "```\n",
    "[\n",
    "    [\"user said this\", \"assistant replied\"],\n",
    "    [\"then user said this\", \"and assistant replied again],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "In the next step we will convert this history into the prompt style for OpenAI, then call the OpenAI API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea21c4a-4508-4a41-b35d-9f66271292d6",
   "metadata": {},
   "source": [
    "#### __An AI Assistant is a very common Gen AI use case__\n",
    "\n",
    "LLM based Chatbots are remarkably effective at conversation:\n",
    "\n",
    "- Friendly, knowledgable __persona__\n",
    "- Ability to maintain __context__ between messages\n",
    "- Subject matter __expertise__ to answer questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ca047-667c-41df-8d75-53fdf33a8a80",
   "metadata": {},
   "source": [
    "#### __The Use of Prompts with our Assistant__\n",
    "\n",
    "__The System Prompt:__\n",
    "\n",
    "- Set tone\n",
    "- Establish ground-rules, like \"If you don't know the answer, just say no.\"\n",
    "- Provide critical background context\n",
    "\n",
    "__Context:__\n",
    "\n",
    "- During the conversation, insert context to give more relevant background information pertaining to the topic\n",
    "\n",
    "__Multi-Shot Prompting:__\n",
    "\n",
    "- Provide example conversations to prime for specific scenarios, train on conversational style and demonstrate complex interactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fb30f9-d109-465c-8fc3-e935a9cbbd84",
   "metadata": {},
   "source": [
    "<img src=\"../../assets/images/prompting-assistants-1.png\" with=\"70%\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c80a3-d9b4-47b1-9c49-e8a989c92ad8",
   "metadata": {},
   "source": [
    "*Screenshot take from the Udemy online course [LLM Engineering: Master AI & Large Language Models](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/) by Ed Donner; go and watch it, it's definitely worth the time*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2eb159-4f31-4262-b1f6-16a2aeed7edc",
   "metadata": {},
   "source": [
    "We will write a function `chat(message, history)` where:\n",
    "**message** is the prompt to use\n",
    "**history** is a list of pairs (a list with sub-lists) of user message with assistant's reply\n",
    "\n",
    "```\n",
    "[\n",
    "    [\"user said this\", \"assistant replied\"],\n",
    "    [\"then user said this\", \"and assistant replied again],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "The `chat`function we're going to write is a __a particular type of function that Gradio expects with it's chat interfaces__. The function will return the next response to this chat. We need to iterate row by row through this structure and the build the following structure out of it:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01250b05-47c2-432b-97fb-b94dbc416cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting history into the prompt style for OpenAI\n",
    "# we write a particular type of function that Gradio expects\n",
    "def chat(message, history):\n",
    "    # (1) setting up list of messages and populating it with the system prompt at the very start\n",
    "    # system_message was defined above\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    # (2) iterating through history\n",
    "    for user_message, assistant_message in history:\n",
    "        # the we append the user message and the assistant message each time\n",
    "        # each row from history turns into two roles in this list\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    # calling openai with the messages\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d967663-8a8a-4021-b203-5cce64a455f4",
   "metadata": {},
   "source": [
    "### Adding Gradio into the Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d024d1-18ab-4582-9578-5caf5a4199ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juergenkober/Library/Caches/pypoetry/virtualenvs/llm-engineering-E34XR2a1-py3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': \"You're a helpful assistant\"}, {'role': 'user', 'content': 'Hello there\"'}]\n",
      "History is:\n",
      "[['Hello there\"', 'Hello! How can I assist you today?']]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': \"You're a helpful assistant\"}, {'role': 'user', 'content': 'Hello there\"'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'I want to buy a tie'}]\n",
      "History is:\n",
      "[['Hello there\"', 'Hello! How can I assist you today?'], ['I want to buy a tie', 'Great! Here are some things to consider when buying a tie:\\n\\n1. **Occasion**: Is it for a formal event, a business setting, or casual wear? This will influence the style and material you choose.\\n\\n2. **Material**: Common materials include silk (for a luxurious look), cotton (more casual), or polyester (affordable and easy to maintain).\\n\\n3. **Color and Pattern**: Solid colors are versatile, while patterns like stripes, florals, or polka dots can add personality. Consider what will coordinate with your wardrobe.\\n\\n4. **Width**: Ties come in various widths. Classic ties are typically around 3 to 3.5 inches wide. Slim ties are usually 2 to 3 inches wide. Make sure to choose a width that complements your frame and the lapels of your jacket.\\n\\n5. **Length**: Most ties are standard length, but if you’re taller than average, you might want to look for \"long\" ties.\\n\\n6. **Care Instructions**: Some ties may require dry cleaning, while others can be washed. Check care labels if maintenance is a concern.\\n\\n7. **Budget**: Determine how much you\\'re willing to spend. Ties can range from very affordable to high-end luxury.\\n\\nIf you have a specific style or occasion in mind, feel free to share, and I can help narrow it down further!']]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': \"You're a helpful assistant\"}, {'role': 'user', 'content': 'Hello there\"'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'I want to buy a tie'}, {'role': 'assistant', 'content': 'Great! Here are some things to consider when buying a tie:\\n\\n1. **Occasion**: Is it for a formal event, a business setting, or casual wear? This will influence the style and material you choose.\\n\\n2. **Material**: Common materials include silk (for a luxurious look), cotton (more casual), or polyester (affordable and easy to maintain).\\n\\n3. **Color and Pattern**: Solid colors are versatile, while patterns like stripes, florals, or polka dots can add personality. Consider what will coordinate with your wardrobe.\\n\\n4. **Width**: Ties come in various widths. Classic ties are typically around 3 to 3.5 inches wide. Slim ties are usually 2 to 3 inches wide. Make sure to choose a width that complements your frame and the lapels of your jacket.\\n\\n5. **Length**: Most ties are standard length, but if you’re taller than average, you might want to look for \"long\" ties.\\n\\n6. **Care Instructions**: Some ties may require dry cleaning, while others can be washed. Check care labels if maintenance is a concern.\\n\\n7. **Budget**: Determine how much you\\'re willing to spend. Ties can range from very affordable to high-end luxury.\\n\\nIf you have a specific style or occasion in mind, feel free to share, and I can help narrow it down further!'}, {'role': 'user', 'content': 'The occasion is a business meeting'}]\n",
      "History is:\n",
      "[['Hello there\"', 'Hello! How can I assist you today?'], ['I want to buy a tie', 'Great! Here are some things to consider when buying a tie:\\n\\n1. **Occasion**: Is it for a formal event, a business setting, or casual wear? This will influence the style and material you choose.\\n\\n2. **Material**: Common materials include silk (for a luxurious look), cotton (more casual), or polyester (affordable and easy to maintain).\\n\\n3. **Color and Pattern**: Solid colors are versatile, while patterns like stripes, florals, or polka dots can add personality. Consider what will coordinate with your wardrobe.\\n\\n4. **Width**: Ties come in various widths. Classic ties are typically around 3 to 3.5 inches wide. Slim ties are usually 2 to 3 inches wide. Make sure to choose a width that complements your frame and the lapels of your jacket.\\n\\n5. **Length**: Most ties are standard length, but if you’re taller than average, you might want to look for \"long\" ties.\\n\\n6. **Care Instructions**: Some ties may require dry cleaning, while others can be washed. Check care labels if maintenance is a concern.\\n\\n7. **Budget**: Determine how much you\\'re willing to spend. Ties can range from very affordable to high-end luxury.\\n\\nIf you have a specific style or occasion in mind, feel free to share, and I can help narrow it down further!'], ['The occasion is a business meeting', \"For a business meeting, you'll want to choose a tie that conveys professionalism while also allowing you to express a bit of your personal style. Here are some suggestions:\\n\\n### Tie Styles for Business Meetings\\n\\n1. **Solid Colors**: A solid tie in a classic color like navy, burgundy, or charcoal can be very professional and versatile.\\n\\n2. **Stripes**: A tie with subtle stripes can add a touch of sophistication. Opt for darker, muted colors for a more formal appearance.\\n\\n3. **Dots or Patterns**: A small polka dot or a conservative geometric pattern can add some character without being overly flashy.\\n\\n4. **Textures**: Consider ties with a slight texture, like a knit tie or a silk blend, which can add depth to your look.\\n\\n### Tips for Choosing the Right Tie\\n\\n- **Coordinate with Your Outfit**: Make sure the tie complements your shirt and suit. For example, if you’re wearing a white or light blue shirt, a deeper-colored tie can create a nice contrast.\\n\\n- **Keep it Simple**: For business meetings, it's often best to avoid ties that are too bold or busy unless you work in a creative industry.\\n\\n- **Check for Quality**: Look for good craftsmanship, such as well-stitched edges and a quality lining. A well-made tie not only looks better but lasts longer.\\n\\n### Suggested Colors\\n- **Navy Blue**\\n- **Burgundy**\\n- **Dark Green**\\n- **Classic Gray**\\n- **Black (for very formal meetings)**\\n\\n### Where to Buy\\n- **Department Stores**: Many carry a wide selection of quality ties.\\n- **Specialty Men’s Shops**: Look for stores that focus on men's professional attire.\\n- **Online Retailers**: Websites like Amazon, Tie Bar, or Nordstrom offer a variety of options with customer reviews to guide your purchase.\\n\\nIf you have more specific preferences or need help with a particular choice, just let me know!\"]]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': \"You're a helpful assistant\"}, {'role': 'user', 'content': 'Hello there\"'}, {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}, {'role': 'user', 'content': 'I want to buy a tie'}, {'role': 'assistant', 'content': 'Great! Here are some things to consider when buying a tie:\\n\\n1. **Occasion**: Is it for a formal event, a business setting, or casual wear? This will influence the style and material you choose.\\n\\n2. **Material**: Common materials include silk (for a luxurious look), cotton (more casual), or polyester (affordable and easy to maintain).\\n\\n3. **Color and Pattern**: Solid colors are versatile, while patterns like stripes, florals, or polka dots can add personality. Consider what will coordinate with your wardrobe.\\n\\n4. **Width**: Ties come in various widths. Classic ties are typically around 3 to 3.5 inches wide. Slim ties are usually 2 to 3 inches wide. Make sure to choose a width that complements your frame and the lapels of your jacket.\\n\\n5. **Length**: Most ties are standard length, but if you’re taller than average, you might want to look for \"long\" ties.\\n\\n6. **Care Instructions**: Some ties may require dry cleaning, while others can be washed. Check care labels if maintenance is a concern.\\n\\n7. **Budget**: Determine how much you\\'re willing to spend. Ties can range from very affordable to high-end luxury.\\n\\nIf you have a specific style or occasion in mind, feel free to share, and I can help narrow it down further!'}, {'role': 'user', 'content': 'The occasion is a business meeting'}, {'role': 'assistant', 'content': \"For a business meeting, you'll want to choose a tie that conveys professionalism while also allowing you to express a bit of your personal style. Here are some suggestions:\\n\\n### Tie Styles for Business Meetings\\n\\n1. **Solid Colors**: A solid tie in a classic color like navy, burgundy, or charcoal can be very professional and versatile.\\n\\n2. **Stripes**: A tie with subtle stripes can add a touch of sophistication. Opt for darker, muted colors for a more formal appearance.\\n\\n3. **Dots or Patterns**: A small polka dot or a conservative geometric pattern can add some character without being overly flashy.\\n\\n4. **Textures**: Consider ties with a slight texture, like a knit tie or a silk blend, which can add depth to your look.\\n\\n### Tips for Choosing the Right Tie\\n\\n- **Coordinate with Your Outfit**: Make sure the tie complements your shirt and suit. For example, if you’re wearing a white or light blue shirt, a deeper-colored tie can create a nice contrast.\\n\\n- **Keep it Simple**: For business meetings, it's often best to avoid ties that are too bold or busy unless you work in a creative industry.\\n\\n- **Check for Quality**: Look for good craftsmanship, such as well-stitched edges and a quality lining. A well-made tie not only looks better but lasts longer.\\n\\n### Suggested Colors\\n- **Navy Blue**\\n- **Burgundy**\\n- **Dark Green**\\n- **Classic Gray**\\n- **Black (for very formal meetings)**\\n\\n### Where to Buy\\n- **Department Stores**: Many carry a wide selection of quality ties.\\n- **Specialty Men’s Shops**: Look for stores that focus on men's professional attire.\\n- **Online Retailers**: Websites like Amazon, Tie Bar, or Nordstrom offer a variety of options with customer reviews to guide your purchase.\\n\\nIf you have more specific preferences or need help with a particular choice, just let me know!\"}, {'role': 'user', 'content': 'what do you think about bright shiny red for a business meeting'}]\n"
     ]
    }
   ],
   "source": [
    "# turn function into user interface that has an instant message style interaction\n",
    "# ChatInterface expects a single function\n",
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33c2c6-9974-41e2-8800-c87acd01cf7a",
   "metadata": {},
   "source": [
    "### Improving the Persona with the system message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f0d6051-a1c9-447e-ac0a-f0150a72c4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a helpful assistant in a clothes store. You should try to gently encourage the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. For example, if the customer says 'I'm looking to buy a hat', you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales evemt.'Encourage the customer to buy hats if they are unsure what to get.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\"\n",
    "system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654ee7d8-ae6f-4f1a-bfbc-78f9a2881ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat function once again, this time without print statements\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    # adding in the list the latest message the user is sending\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73501cb-c681-406b-b513-f6d5bcd47221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juergenkober/Library/Caches/pypoetry/virtualenvs/llm-engineering-E34XR2a1-py3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0486e04-53b3-4d64-8eec-7e1a59436255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding another line to the system message\n",
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "751c5982-8967-48ca-a751-6d70d39f2cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a helpful assistant in a clothes store. You should try to gently encourage the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. For example, if the customer says 'I'm looking to buy a hat', you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales evemt.'Encourage the customer to buy hats if they are unsure what to get.\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, but remind the customer to look at hats!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d25f9e82-4514-4a62-bd38-5cadd3dd2cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juergenkober/Library/Caches/pypoetry/virtualenvs/llm-engineering-E34XR2a1-py3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddea59c7-f51e-4dbe-94ea-7224d17bbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one more hacky adjustment to the system message\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "    # this is very hacky, don't try this at home kids!\n",
    "    if 'belt' in message:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"For added context, the store does not sell belts, \\\n",
    "but be sure to point out other items on sale\"})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "637e0fb3-c5d5-4311-932b-700bc60ec793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juergenkober/Library/Caches/pypoetry/virtualenvs/llm-engineering-E34XR2a1-py3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:229: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa58c0c-b689-4ea9-bc4b-7e0d98a74279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
