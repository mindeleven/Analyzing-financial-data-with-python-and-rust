{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfaec8d3-0780-43e0-8358-43aaca7a5fe1",
   "metadata": {},
   "source": [
    "## Agent Framework: Multimodal AI Assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36033d90-fdaa-4328-a7f3-f7c3616fd7a3",
   "metadata": {},
   "source": [
    "*[Coding along with the Udemy online course [LLM Engineering: Master AI & Large Language Models](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/) by Ed Donner; GitHub repo can be found at [github.com/ed-donner/llm_engineering](https://github.com/ed-donner/llm_engineering)]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c9113-5e75-4ac5-9aa0-6652e4aaebba",
   "metadata": {},
   "source": [
    "### The Agent Framework\n",
    "\n",
    "The term 'Agentic AI' and Agentization is an umbrella term that refers to a number of techniques, such as:\n",
    "\n",
    "1. Breaking a complex problem into smaller steps, with multiple LLMs carrying out specialized tasks\n",
    "2. The ability for LLMs to use Tools to give them additional capabilities\n",
    "3. The 'Agent Environment' which allows Agents to collaborate\n",
    "4. An LLM can act as the Planner, dividing bigger tasks into smaller ones for the specialists\n",
    "5. The concept of an Agent having autonomy / agency, beyond just responding to a prompt - such as Memory\n",
    "\n",
    "(Source: [Build a Multimodal AI Agent](https://www.udemy.com/course/llm-engineering-master-ai-and-large-language-models/learn/lecture/45775535))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4c98c-00fe-4795-a89f-a81a7f7e7ec3",
   "metadata": {},
   "source": [
    "## Project: Creating a Multimodal AI Assistant Using Agents and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c003bd1a-7623-4a7f-a2d4-fb87273cf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "# some imports for handling images\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import datetime\n",
    "import gradio as gr\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb9af51-a4d3-4cbf-a4ef-eee4bc87af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and sent your api key to github\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = pd.read_csv(\"~/tmp/chat_gpt/agentic-design-1.txt\", sep=\" \", header=None)[0][0]\n",
    "\n",
    "# connect to openai\n",
    "openai = OpenAI(api_key=openai_api_key)\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "print(\"Don't be a fool and sent your api key to github\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a10c91-0960-4ca2-ad00-cba212f1530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99716727-32b4-44ac-954a-14abd766b364",
   "metadata": {},
   "source": [
    "#### __Image Generation with DALL-E-3__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7104a3b9-9592-48bb-a2cf-1436cdcabaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    # call to images.generate() to generate images\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\",\n",
    "            size=\"1024x1024\", # smallest size in dall-e-3\n",
    "            n=1, # we want one image back\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    image_base64 = image_response.data[0].b64_json # base64 encoded image\n",
    "    image_data = base64.b64decode(image_base64) # decoding image data\n",
    "\n",
    "    # saving image to disk\n",
    "    img = Image.open(BytesIO(image_data))\n",
    "    image_name = \"../../assets/dall-e-images/\" + city + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") + \".jpg\"\n",
    "    img.save(image_name, \"JPEG\")\n",
    "    \n",
    "    return Image.open(BytesIO(image_data)) # return image with Image.open function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f891d-1f5e-473a-8c4b-c11b44514961",
   "metadata": {},
   "source": [
    "#### __OpenAI Audio Generation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc7160b-1b9d-4faa-8d72-0a52a9cb030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def talker(message):\n",
    "    response = openai.audio.speech.create(\n",
    "      model=\"tts-1\", # text to speach model\n",
    "      voice=\"onyx\", # providing onyx as a voice; alternatively alloy\n",
    "      input=message\n",
    "    )\n",
    "    \n",
    "    audio_stream = BytesIO(response.content) # create bytes object\n",
    "    audio = AudioSegment.from_file(audio_stream, format=\"mp3\")\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23e997-1a94-4339-9b16-d068e8dc12fb",
   "metadata": {},
   "source": [
    "#### __Handling the Tool Call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b025d613-dab9-45ef-b316-86f54f8af07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13741414-5241-4791-bf36-7de79fc596e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3361eb5e-06ee-4e3f-97a0-373cd8c57a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fce7fe3-0ea5-4865-815f-1eba37674159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    city = arguments.get('destination_city')\n",
    "    price = get_ticket_price(city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
    "        \"tool_call_id\": message.tool_calls[0].id\n",
    "    }\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b484de-d9b3-4eb6-8957-1fd3a968a668",
   "metadata": {},
   "source": [
    "#### __The Chat Method__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1800fc-091f-45ab-8660-57547c211ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the chat method that gradio will need\n",
    "def chat(message, history):\n",
    "    image = None\n",
    "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for human, assistant in history:\n",
    "        conversation.append({\"role\": \"user\", \"content\": human})\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "    conversation.append({\"role\": \"user\", \"content\": message})\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=conversation, tools=tools)\n",
    "\n",
    "    # finding out if the model wants to call a tool\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = tool_call = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        conversation.append(message)\n",
    "        conversation.append(response)\n",
    "        # if the model needs to run the tools to get a price we've also the artist to generate an image\n",
    "        image = artist(city)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=conversation)\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    # once the response is collected we call talker to speak the response\n",
    "    talker(reply)\n",
    "    return reply, image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b3bd2-680d-4104-b8f4-680ea25bf002",
   "metadata": {},
   "source": [
    "#### __The Gradio Interface__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20f25b48-bb0c-4353-9fec-19c99bcee494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juergenkober/Library/Caches/pypoetry/virtualenvs/llm-engineering-E34XR2a1-py3.12/lib/python3.12/site-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/7c/6tn50bjd30l3zb0p8_7mr94m0000gn/T/tmpqx7qevw7.wav':\n",
      "  Duration: 00:00:01.97, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   1.93 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/7c/6tn50bjd30l3zb0p8_7mr94m0000gn/T/tmpidfzqbrx.wav':\n",
      "  Duration: 00:00:02.83, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   2.78 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool get_ticket_price called for London\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/7c/6tn50bjd30l3zb0p8_7mr94m0000gn/T/tmp5vsmdtlo.wav':\n",
      "  Duration: 00:00:06.12, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   6.02 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool get_ticket_price called for Tokyo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/7c/6tn50bjd30l3zb0p8_7mr94m0000gn/T/tmpqdw4w9rp.wav':\n",
      "  Duration: 00:00:07.01, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   6.96 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/7c/6tn50bjd30l3zb0p8_7mr94m0000gn/T/tmpozsnoqhd.wav':\n",
      "  Duration: 00:00:04.30, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   4.22 M-A: -0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/7c/6tn50bjd30l3zb0p8_7mr94m0000gn/T/tmpqli535v4.wav':\n",
      "  Duration: 00:00:04.03, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   3.97 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool get_ticket_price called for Paris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/7c/6tn50bjd30l3zb0p8_7mr94m0000gn/T/tmp82_m6e_a.wav':\n",
      "  Duration: 00:00:04.63, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   4.57 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tool get_ticket_price called for Berlin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/7c/6tn50bjd30l3zb0p8_7mr94m0000gn/T/tmp2y08l724.wav':\n",
      "  Duration: 00:00:06.14, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "   6.04 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# More involved Gradio code as we're not using the preset Chat interface\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500)\n",
    "        image_output = gr.Image(height=500)\n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "    with gr.Row():\n",
    "        clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "\n",
    "    def bot(history):\n",
    "        user_message = history[-1][0]\n",
    "        bot_message, image = chat(user_message, history[:-1])\n",
    "        history[-1][1] = bot_message\n",
    "        return history, image\n",
    "\n",
    "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot, chatbot, [chatbot, image_output]\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5118fe3-89f7-4ceb-9714-58ddb1e0b01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
