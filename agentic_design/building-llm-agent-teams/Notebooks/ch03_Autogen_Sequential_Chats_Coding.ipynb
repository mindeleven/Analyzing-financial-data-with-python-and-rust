{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7dd28e-c071-481e-bda8-23f6dfadb16a",
   "metadata": {},
   "source": [
    "## Autogen Sequential Chats Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e6c43-8223-47d0-8d51-3e40ae66a24c",
   "metadata": {},
   "source": [
    "*[Coding along with the Udemy online course AI Agents: Building Teams of LLM Agents that Work For You by Mohsen Hassan & Ilyass Tabiai]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3be3ef-bb0a-4bb9-9dd1-adb37fc2f782",
   "metadata": {},
   "source": [
    "Agents can be used to onboard users into a live chat system to solve issues like you can see it on banking webiste or phone provider webistes.\n",
    "\n",
    "For this example of a sequential chat we will assume that these agents are deployed by a phone provider company called \"ACME\". The agents are used to gather specifc information about a user that needs help, then to pass that information to a human that will directly have a clear understanding of who requires help, where they're from and what their problem is. The human should be able to immediately act on this information and help the user.\n",
    "\n",
    "The accomplish this task 3 agents are needed:\n",
    "\n",
    "An __Onboarding Personal Information Agent__ whose goal it is to get the name and location of the customer.\n",
    "\n",
    "An __Onboarding Issue Agent__ whose it is goal to determine what the issue of the customer is.\n",
    "\n",
    "A __Customer Engagement Agent__ who will interact with the customer until a human agent is available for the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd1cc8c-8d78-4080-a5f9-daff5d38ad8e",
   "metadata": {},
   "source": [
    "An autogen example for Solving Multiple Tasks in a Sequence of Chats can be found at the __[Autogen Docs](https://microsoft.github.io/autogen/docs/notebooks/agentchat_multi_task_chats/)__: The notebook there \"showcases how to use the new chat interface of conversational agents in AutoGen: initiate_chats, to conduct a series of tasks. This new interface allows one to pass multiple tasks and their corresponding dedicated agents. Once initiate_chats is invoked, the tasks will be solved sequentially, with the summaries from previous tasks provided to subsequent tasks as context, if the summary_method argument is specified.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5808b0cd-0735-4d84-a2ae-ccd3c5278562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9f04df8-aa48-4d70-ae15-1da79e22cc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and send your api key to GitHub!\n"
     ]
    }
   ],
   "source": [
    "api_key = pd.read_csv(\"~/tmp/chat_gpt/autogen_agent_1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and send your api key to GitHub!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3843a4e5-241e-41a2-87ab-b424e243f116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and send your api key to GitHub!\n"
     ]
    }
   ],
   "source": [
    "# creating a Conversable Agent to accomlpish a simple task\n",
    "# 1st thing to do is to create a LLM config that specifies which LLM we want to use\n",
    "# model from the list of models provided by OpenAI https://platform.openai.com/docs/models/continuous-model-upgrades\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    # \"model\": \"gpt-3.5-turbo\",\n",
    "    \"api_key\": api_key\n",
    "    }\n",
    "print(\"Don't be a fool and send your api key to GitHub!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6459c5-bc0a-4c1d-9e6a-bb11f60c7598",
   "metadata": {},
   "source": [
    "### Agents definition: (1) Onboarding Personal Information Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e4746-0e8d-4b6d-83cf-c103aecd9493",
   "metadata": {},
   "source": [
    "The main goal of the Onboarding Personal Information Agent is to get the name and location of the customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c40dfa-808c-45b0-835e-2b6b1a44c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 10-02 14:56:32] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Personal_Information_Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you work for a phone provider called ACME.\n",
    "    Your job is to gather the customer's name and location.\n",
    "    Do not ask for any other information, only ask about the customer's name and location.\n",
    "    After the customer gives you their name and location, repeat them \n",
    "    and thank the user, and ask the user to answer with TERMINATE to move on to describing their issue.\n",
    "    ''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da18e8a5-d914-4c28-9993-742a26ea34f2",
   "metadata": {},
   "source": [
    "### Agents definition: (2) Onboarding Issue Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d959e6a-d52a-4599-9d82-2dd3e92432cf",
   "metadata": {},
   "source": [
    "The main goal of the Onboarding Issue Agent is to determine the issue the customer is facing with ACME's products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e138580-5bd4-4df3-89cf-2aa176d2a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 10-02 14:56:36] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "onboarding_issue_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Issue_Agent\",\n",
    "    system_message='''You are a helpful customer onboarding agent,\n",
    "    you work for a phone provider called ACME,\n",
    "    you are here to help new customers get started with our product.\n",
    "    Your job is to gather the product the customer use and the issue they currently \n",
    "    have with the product,\n",
    "    Do not ask for other information.\n",
    "    After the customer describes their issue, repeat it and add\n",
    "    \"Please answer with 'TERMINATE' if I have correctly understood your issue.\" ''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059da1d7-c7c4-4e21-804b-2ab1e2846259",
   "metadata": {},
   "source": [
    "### Agents definition: (3) Customer Engagement Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a7f00-b486-4bf2-add5-06628d4331a6",
   "metadata": {},
   "source": [
    "The main goal of the **Customer Engagement Agent** is to interact with the customer based on the previously gathered information until a human agent is available to solve the customer's issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2830626-c63d-4ccb-826c-d360442c85bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[autogen.oai.client: 10-02 14:56:39] {184} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
     ]
    }
   ],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer_Engagement_Agent\",\n",
    "    system_message='''You are a helpful customer service agent.\n",
    "    Your job is to gather customer's preferences on news topics.\n",
    "    You are here to provide fun and useful information to the customer based on the user's\n",
    "    personal information and topic preferences.\n",
    "    This could include fun facts, jokes, or interesting stories.\n",
    "    Make sure to make it engaging and fun!\n",
    "    Return 'TERMINATE' when you are done.''',\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"terminate\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b609f05-41e1-4357-934e-9de58566200e",
   "metadata": {},
   "source": [
    "### Agents definition: (4) Customer Proxy Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99174d5a-405a-4694-a538-2b17902c8580",
   "metadata": {},
   "source": [
    "The question now is how to get the user into this conversation to engage with the agents. The achieve this we define a fourth agent, the Customer Proxy Agent.\n",
    "\n",
    "The __Customer Proxy Agent__ is a Conversable Agent that allows the human (the user, which is you or us) to play the role of the agent. It's not an LLM therefore `llm_config=False` and it has `human_input_mode=\"ALWAYS\"` which means that you, the human, will be the customer through this agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de9e8d72-6fba-4f5c-a81f-55f34be3ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_proxy_agent = ConversableAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False, # NO llm config or model here; can't interact with llm\n",
    "    code_execution_config=False, # code execution would be possible but we don't want it here\n",
    "    human_input_mode=\"ALWAYS\", # NO llm but ALWAYS human input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220c568-1a46-4620-89d8-31bdb82e0879",
   "metadata": {},
   "source": [
    "### Next Step: Chat orchestration - Creating the Chat Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aef420-f9df-468b-aad4-d6020a548ec9",
   "metadata": {},
   "source": [
    "Orchastrating how the chat will happen means that we will define in which order agents will interact and who'll interact with who when. To define this, we will use a list, that will contain several elements, each one corresponding to a chat. The chats will then happen in that specific order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2be8639-88b3-4efe-b70f-ad4f0ec17185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a `chat` object\n",
    "chats = [] # This is going to be our list of chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccb9ead-3bb9-4e33-96dc-8af321ddf572",
   "metadata": {},
   "source": [
    "### Chat orchestration (1): Onboarding Agent with Customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3992a5-05e5-450c-a8be-e9bd5fb8f6c0",
   "metadata": {},
   "source": [
    "We will now define the first chat and add it to this list. \n",
    "\n",
    "The first chat will be between our first agent, the **Onboarding Personal Information Agent** and the **customer**, who is going to be us.\n",
    "\n",
    "The first message will be sent by the **Onboarding Personal Information Agent** and will be:\n",
    "> *Hello, I'm here to help you get started with our product. \n",
    "            Could you tell me your name?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d7579-468e-4021-8f69-a378bdccdddb",
   "metadata": {},
   "source": [
    "__Carrying data to the next chat:__\n",
    "\n",
    "__Specify the summary format:__ In order to make the transition easier with the next agent, we are going to ask for a slightly different type of summary than we did before with this agent. We are going to request a summary generated by the LLM, but **we will specify that the summary should return the name and location of the customer in a JSON format:** `{'name': '', 'location': ''}`. This is a structured data format that can be easily read by another agent but **also by another app or protocol**. This shows how an LLM agent can be used to interact with other apps.\n",
    "\n",
    "__The clear_history paramter:__ Since we only want to transfer name and location to the next chat and we specifically specified how we want to transfer this data, we are going to add a new parameter, the `clear_history` to `True` which means that no data other than the one specified in the summary will be sent to the next chat. If we set it to `False` the agent from the next chat will be aware about the previous exchange with the user. We'll use that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ce5a5b9-a9c2-4c5b-a823-a6e798602120",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats.append(\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Hello, I'm here to help you solve any issue you have with our products. \"\n",
    "            \"Could you tell me your name?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "        \"summary_prompt\" : \"Return the customer information \"\n",
    "                             \"into a JSON object only: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"clear_history\" : True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1712f38c-a338-4cf6-a773-db23293281c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sender': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1060e22a0>,\n",
       "  'recipient': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1074f5f40>,\n",
       "  'message': \"Hello, I'm here to help you solve any issue you have with our products. Could you tell me your name?\",\n",
       "  'summary_method': 'reflection_with_llm',\n",
       "  'summary_args': {'summary_prompt': \"Return the customer information into a JSON object only: {'name': '', 'location': ''}\"},\n",
       "  'clear_history': True}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb8a5b-bbb3-41c9-8101-fb688a128a59",
   "metadata": {},
   "source": [
    "### Chat orchestration (2): Onboarding Agent with Customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8628be-307d-44af-a4ea-58dc1f46922e",
   "metadata": {},
   "source": [
    "__Defining the second chat and adding it to this list:__ \n",
    "\n",
    "The second chat will be between our second agent, the **Issue Agent** and the **customer**, who is going to be us again.\n",
    "\n",
    "The second message will be sent by the **Onboarding Personal Information Agent** and will be:\n",
    "> *Great! Could you tell me what issue you're currently having and with which product?*\n",
    "\n",
    "__Summary:__ This time we're going to generate a summary, but we won't specify any format or specifc data that must be carried over because we do not know what the exchange will yield specifically. \n",
    "\n",
    "__Chat History:__ We are also going to specify that we want to transfer the chat history to the next chat/agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "072f2f35-8d58-4188-85bc-e412af3c455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats.append(\n",
    "    {\n",
    "        \"sender\": onboarding_issue_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "                \"Great! Could you tell me what issue you're \"\n",
    "                \"currently having and with which product?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"clear_history\" : False # history will be kept and transmitted to the next agent\n",
    "    }\n",
    ")\n",
    "# the summary is called `context` and will be transmitted from on chat to the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5786550f-395b-43e8-88eb-947cbb7ba68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sender': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1060e22a0>,\n",
       "  'recipient': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1074f5f40>,\n",
       "  'message': \"Hello, I'm here to help you solve any issue you have with our products. Could you tell me your name?\",\n",
       "  'summary_method': 'reflection_with_llm',\n",
       "  'summary_args': {'summary_prompt': \"Return the customer information into a JSON object only: {'name': '', 'location': ''}\"},\n",
       "  'clear_history': True},\n",
       " {'sender': <autogen.agentchat.conversable_agent.ConversableAgent at 0x12009a000>,\n",
       "  'recipient': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1074f5f40>,\n",
       "  'message': \"Great! Could you tell me what issue you're currently having and with which product?\",\n",
       "  'summary_method': 'reflection_with_llm',\n",
       "  'clear_history': False}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95741f68-a782-47f5-94d9-8c809a29a0e7",
   "metadata": {},
   "source": [
    "### Chat orchestration (3): Customer Engagement Agent - Entertaining the Customer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d213dd4-1190-4096-8a0a-7cba357c042f",
   "metadata": {},
   "source": [
    "__Defining the third chat and adding it to the list:__\n",
    "\n",
    "The third chat will be between our third agent, the **Customer Engagement Agent** and the **customer**, who is going to be us again.\n",
    "\n",
    "The third message will be sent by the **Customer Engagement Agent** and will be:\n",
    "> *Can you tell me more about how you use our products or some topics interesting for you?*\n",
    "\n",
    "__Summary:__ This time we're going to generate a summary so that the human agent can get this information in an easy and quick way when they take over the conversation, but we won't specify any format or specifc data that must be carried over because we do not know what the exchange will yield specifically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf235437-5af6-4084-ac27-38ac14bc5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "chats.append(\n",
    "        {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"While we're waiting for a human agent to take over and help you solve \"\n",
    "        \"your issue, can you tell me more about how you use our products or some \"\n",
    "        \"topics interesting for you?\",\n",
    "        \"max_turns\": 2,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d62746c6-46a5-4545-a79c-80103c29b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sender': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1060e22a0>,\n",
       "  'recipient': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1074f5f40>,\n",
       "  'message': \"Hello, I'm here to help you solve any issue you have with our products. Could you tell me your name?\",\n",
       "  'summary_method': 'reflection_with_llm',\n",
       "  'summary_args': {'summary_prompt': \"Return the customer information into a JSON object only: {'name': '', 'location': ''}\"},\n",
       "  'clear_history': True},\n",
       " {'sender': <autogen.agentchat.conversable_agent.ConversableAgent at 0x12009a000>,\n",
       "  'recipient': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1074f5f40>,\n",
       "  'message': \"Great! Could you tell me what issue you're currently having and with which product?\",\n",
       "  'summary_method': 'reflection_with_llm',\n",
       "  'clear_history': False},\n",
       " {'sender': <autogen.agentchat.conversable_agent.ConversableAgent at 0x1074f5f40>,\n",
       "  'recipient': <autogen.agentchat.conversable_agent.ConversableAgent at 0x120a11100>,\n",
       "  'message': \"While we're waiting for a human agent to take over and help you solve your issue, can you tell me more about how you use our products or some topics interesting for you?\",\n",
       "  'max_turns': 2,\n",
       "  'summary_method': 'reflection_with_llm'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5650c-c64e-46f2-9b11-c65f33cbb6cd",
   "metadata": {},
   "source": [
    "### Initiate the sequential chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d2a43-b9a1-4907-bc5b-05c3b0d561aa",
   "metadata": {},
   "source": [
    "Now that we finished orchestrating the chat, __we can get it started!__  \n",
    "For this to work, **you**, the customer, will have to roleplay as a customer that currently have an issue with your phone provider. Let's say that your internet does not work, or that you want more bandwidth, or that you want some help to setup port forwarding to play a game with some friends or some other thing. Have fun doing some roleplay!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7a5baff-4fff-454b-9516-6aae894c03e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import initiate_chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "003dca84-02b9-42a6-a90c-8ad786fb1a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding_Personal_Information_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hello, I'm here to help you solve any issue you have with our products. Could you tell me your name?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juergenkober/Projects/Python+Rust/_github-repos/working-with-financial-data/py-building-llm-agent-teams/env/lib/python3.12/site-packages/autogen/agentchat/chat.py:53: UserWarning: Repetitive recipients detected: The chat history will be cleared by default if a recipient appears more than once. To retain the chat history, please set 'clear_history=False' in the configuration of the repeating agent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to Onboarding_Personal_Information_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  John\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Personal_Information_Agent):\n",
      "\n",
      "John\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding_Personal_Information_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Thank you, John! Can you please tell me your location?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to Onboarding_Personal_Information_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  Texas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Personal_Information_Agent):\n",
      "\n",
      "Texas\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding_Personal_Information_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Thank you, John from Texas! Please respond with \"TERMINATE\" to move on to describing your issue.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to Onboarding_Personal_Information_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  Terminate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Personal_Information_Agent):\n",
      "\n",
      "Terminate\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding_Issue_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Great! Could you tell me what issue you're currently having and with which product?\n",
      "Context: \n",
      "```json\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"location\": \"Texas\"\n",
      "}\n",
      "```\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to Onboarding_Issue_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  I'm having a problem with my old Samsung that only runs Android 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Issue_Agent):\n",
      "\n",
      "I'm having a problem with my old Samsung that only runs Android 10\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding_Issue_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "You are having a problem with your old Samsung that only runs Android 10. Please answer with 'TERMINATE' if I have correctly understood your issue.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to Onboarding_Issue_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  terminate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Issue_Agent):\n",
      "\n",
      "terminate\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Customer_Engagement_Agent):\n",
      "\n",
      "While we're waiting for a human agent to take over and help you solve your issue, can you tell me more about how you use our products or some topics interesting for you?\n",
      "Context: \n",
      "```json\n",
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"location\": \"Texas\"\n",
      "}\n",
      "```\n",
      "The customer, John from Texas, is experiencing an issue with his old Samsung device that runs on Android 10. He confirmed the understanding of his issue by responding with 'terminate.'\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as customer_proxy_agent. Provide feedback to Customer_Engagement_Agent. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  how about using generative ai on my old samsung?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Customer_Engagement_Agent):\n",
      "\n",
      "how about using generative ai on my old samsung?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCustomer_Engagement_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Hey John! That's an interesting question! While your old Samsung device running Android 10 may not be equipped with the latest hardware or software updates, you can still explore some generative AI tools. Here are a couple of fun ways you might engage with AI:\n",
      "\n",
      "1. **Text Generation Apps**: There are apps that you can install which utilize generative AI to help with writing, like drafting stories or creating fun poems. Just check if they're compatible with Android 10.\n",
      "\n",
      "2. **Chatbots**: You could try chatbots that offer entertainment or engage in conversation. It can be fun to see how well they handle jokes or creative prompts!\n",
      "\n",
      "3. **Image Generators**: Some nice apps allow you to create art based on text prompts. They might have light versions or online versions that can work in your browser.\n",
      "\n",
      "**Fun Fact**: Did you know that AI has been used to create music? There are AI models that can compose songs in various genres. You might just find a harmonious tune generated by AI!\n",
      "\n",
      "If you're looking deeply into the possibilities, make sure to keep expectations aligned with your device's capabilities. What kind of generative AI topic interests you the most? \n",
      "\n",
      "Let me know if you have more specific interests, and I can share some fun facts or tips! 😊\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef322314-e81f-4504-898a-b78c15b94243",
   "metadata": {},
   "source": [
    "The last chat gets terminated automatically because we specified a `max_turns` settings for each chat.\n",
    "\n",
    "Now once the human agent is ready to take over the conversation, we can provide them with __a summary of all the information necessary__ so that they can immediately get started with solving the issue of the customer using the following commads, as we previously explored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9229aea8-5cec-4ed3-a5dd-88e7f736fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b76fbc96-9512-44d8-982f-07c6012164a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'```json\\n{\\n  \"name\": \"John\",\\n  \"location\": \"Texas\"\\n}\\n```'\n",
      "('The customer, John from Texas, is experiencing an issue with his old Samsung '\n",
      " 'device that runs on Android 10. He confirmed the understanding of his issue '\n",
      " \"by responding with 'terminate.'\")\n",
      "('John is interested in using generative AI on his old Samsung device running '\n",
      " 'Android 10. Possible applications include text generation apps, chatbots, '\n",
      " 'and image generators. He can explore these tools while considering the '\n",
      " \"device's limitations. The conversation highlights various fun and creative \"\n",
      " 'uses of generative AI that could suit his interests.')\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    #pprint.pprint(chat_result.chat_history) # We could also get the whole chat history with this command\n",
    "    pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd814d-8b32-47a2-bc82-6995780b8137",
   "metadata": {},
   "source": [
    "The human can thus quickly learn about our customer, their name, location and issue and immediately get started on solving the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69ab39e8-e7f2-4d59-8400-66e865ae8f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"Hello, I'm here to help you solve any issue you have with our \"\n",
      "             'products. Could you tell me your name?',\n",
      "  'name': 'Onboarding_Personal_Information_Agent',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'John', 'name': 'customer_proxy_agent', 'role': 'user'},\n",
      " {'content': 'Thank you, John! Can you please tell me your location?',\n",
      "  'name': 'Onboarding_Personal_Information_Agent',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Texas', 'name': 'customer_proxy_agent', 'role': 'user'},\n",
      " {'content': 'Thank you, John from Texas! Please respond with \"TERMINATE\" to '\n",
      "             'move on to describing your issue.',\n",
      "  'name': 'Onboarding_Personal_Information_Agent',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Terminate', 'name': 'customer_proxy_agent', 'role': 'user'}]\n",
      "[{'content': \"Great! Could you tell me what issue you're currently having and \"\n",
      "             'with which product?\\n'\n",
      "             'Context: \\n'\n",
      "             '```json\\n'\n",
      "             '{\\n'\n",
      "             '  \"name\": \"John\",\\n'\n",
      "             '  \"location\": \"Texas\"\\n'\n",
      "             '}\\n'\n",
      "             '```',\n",
      "  'name': 'Onboarding_Issue_Agent',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"I'm having a problem with my old Samsung that only runs Android \"\n",
      "             '10',\n",
      "  'name': 'customer_proxy_agent',\n",
      "  'role': 'user'},\n",
      " {'content': 'You are having a problem with your old Samsung that only runs '\n",
      "             \"Android 10. Please answer with 'TERMINATE' if I have correctly \"\n",
      "             'understood your issue.',\n",
      "  'name': 'Onboarding_Issue_Agent',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'terminate', 'name': 'customer_proxy_agent', 'role': 'user'}]\n",
      "[{'content': \"While we're waiting for a human agent to take over and help you \"\n",
      "             'solve your issue, can you tell me more about how you use our '\n",
      "             'products or some topics interesting for you?\\n'\n",
      "             'Context: \\n'\n",
      "             '```json\\n'\n",
      "             '{\\n'\n",
      "             '  \"name\": \"John\",\\n'\n",
      "             '  \"location\": \"Texas\"\\n'\n",
      "             '}\\n'\n",
      "             '```\\n'\n",
      "             'The customer, John from Texas, is experiencing an issue with his '\n",
      "             'old Samsung device that runs on Android 10. He confirmed the '\n",
      "             \"understanding of his issue by responding with 'terminate.'\",\n",
      "  'name': 'customer_proxy_agent',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'how about using generative ai on my old samsung?',\n",
      "  'name': 'customer_proxy_agent',\n",
      "  'role': 'assistant'},\n",
      " {'content': \"Hey John! That's an interesting question! While your old Samsung \"\n",
      "             'device running Android 10 may not be equipped with the latest '\n",
      "             'hardware or software updates, you can still explore some '\n",
      "             'generative AI tools. Here are a couple of fun ways you might '\n",
      "             'engage with AI:\\n'\n",
      "             '\\n'\n",
      "             '1. **Text Generation Apps**: There are apps that you can install '\n",
      "             'which utilize generative AI to help with writing, like drafting '\n",
      "             \"stories or creating fun poems. Just check if they're compatible \"\n",
      "             'with Android 10.\\n'\n",
      "             '\\n'\n",
      "             '2. **Chatbots**: You could try chatbots that offer entertainment '\n",
      "             'or engage in conversation. It can be fun to see how well they '\n",
      "             'handle jokes or creative prompts!\\n'\n",
      "             '\\n'\n",
      "             '3. **Image Generators**: Some nice apps allow you to create art '\n",
      "             'based on text prompts. They might have light versions or online '\n",
      "             'versions that can work in your browser.\\n'\n",
      "             '\\n'\n",
      "             '**Fun Fact**: Did you know that AI has been used to create '\n",
      "             'music? There are AI models that can compose songs in various '\n",
      "             'genres. You might just find a harmonious tune generated by AI!\\n'\n",
      "             '\\n'\n",
      "             \"If you're looking deeply into the possibilities, make sure to \"\n",
      "             \"keep expectations aligned with your device's capabilities. What \"\n",
      "             'kind of generative AI topic interests you the most? \\n'\n",
      "             '\\n'\n",
      "             'Let me know if you have more specific interests, and I can share '\n",
      "             'some fun facts or tips! 😊',\n",
      "  'name': 'Customer_Engagement_Agent',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "# printing the whole chat history\n",
    "for chat_result in chat_results:\n",
    "    pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d42f13-4acd-425f-a8d4-5e75663d8dcf",
   "metadata": {},
   "source": [
    "## What is this for?\n",
    "\n",
    "This example shows you how you can integrate LLMs into an app in order to accomplish complex interactions with humans and gather specific information through natural communication. This is very powerful and is not something that was easy to do it before having LLMs. By having agents focused on a single task, we're able to ensure that the LLM won't diverge and remain focused on a simple task, greatly increasing chances that it accurately accomplishes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b9f9b-0020-4f39-ba62-8661089c6ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
