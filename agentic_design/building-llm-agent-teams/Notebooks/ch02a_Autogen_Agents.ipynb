{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e3ed12-0269-494c-9bea-9a844ea12d67",
   "metadata": {},
   "source": [
    "## Autogen Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf010a7-ee81-44a0-91fb-545ec729e3bb",
   "metadata": {},
   "source": [
    "*[Coding along with the Udemy online course AI Agents: Building Teams of LLM Agents that Work For You by Mohsen Hassan & Ilyass Tabiai]*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df96a586-6fb2-405d-82f9-d821f9f19087",
   "metadata": {},
   "source": [
    "**AutoGen is an open-source framework that leverages multiple agents to enable complex workflows.**\n",
    "\n",
    "- Autogen was developed by Microsoft to create advanced LLM-based applications.\n",
    "- Autogen is designed to enable you to orchestrate multi-agent conversations that seamlessly integrate LLMs, human input and other tools.\n",
    "- Autogen is supported by Microsoft, which gives it long term viability and was designed to specifically work with OpenAI, so it will be the framework we will be using in this class for agentic design.\n",
    "\n",
    "**An online tutorial can be found at [Getting Started with AutoGen](https://microsoft.github.io/autogen/docs/Getting-Started).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7baed5-7848-4482-afab-5d61d2921925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58874505-b0f8-480d-b8d2-20bc6dd2c5aa",
   "metadata": {},
   "source": [
    "Importing `autogen` returned the following error:<br/>\n",
    "`flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.`\n",
    "\n",
    "The temporary solution to solve this was to create a constraints.txt file with the following content:\n",
    "\n",
    "`flaml==2.2.0`\n",
    "\n",
    "Then running: `pip install -c constraints.txt autogen`\n",
    "\n",
    "Following the suggestion at https://github.com/microsoft/autogen/issues/3548.\n",
    "\n",
    "*FLAML @ https://microsoft.github.io/FLAML/ is \"A Fast Library for Automated Machine Learning & Tuning.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1f800-24f9-4f24-9992-9777a78fd10c",
   "metadata": {},
   "source": [
    "<img decoding=\"async\" loading=\"lazy\" alt=\"AutoGen Overview\" src=\"../assets/images/microsoft-autogen-1.png\" width=\"75%\">\n",
    "<br/><i>Screenshot from Getting Started with AutoGen @ https://microsoft.github.io/autogen/docs/Getting-Started</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc15a7-22c8-45d4-ab7c-160ad7899682",
   "metadata": {},
   "source": [
    "## Conversable Agent\n",
    "\n",
    "* AutoGen offers a unified multi-agent conversation framework that simplifies the orchestration and automation of complex LLM workflows the Conversable Agent class. These agents can collectively perform tasks autonomously or with human feedback.\n",
    "* Conversable Agents are:\n",
    "    * **Conversable**: Agents can send and receive messages from other agents or humans; they can initate and continue a conversation seamlessly.\n",
    "    * **Customizable**: They can be customized to integrate LLMs, human intervention, tools/skills (code) or combinations of these.\n",
    "    * Of two subcategories:\n",
    "        * **AssistantAgent**: This subcategory represents AI assistants, that use LLMs (such as GPT-4) by default. It can generate Python code for users to execute based on task descriptions. Additionally, it can receive execution results (from code or other agents) and suggest corrections or bug fixes.\n",
    "        * **UserProxyAgent**:  This subcategory acts as a proxy agent for humans. It solicits human input as its reply during interactions. It also has the capability to execute code and call functions or tools. Code execution can be automatically triggered when an executable code block is detected in the received message.\n",
    "\n",
    "Let's create a Conversable Agent to accomlpish a simple task. Before doing that, we will have to create a LLM config that specifies which LLM we want to use. Here we will again use chatGPT3.5 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1145aa7e-8881-4bfe-be34-67fe600fc549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066913e2-3039-49d0-82e0-5422c14fbec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and send your api key to GitHub!\n"
     ]
    }
   ],
   "source": [
    "api_key = pd.read_csv(\"~/tmp/chat_gpt/agentic-design-1.txt\", sep=\" \", header=None)[0][0]\n",
    "print(\"Don't be a fool and send your api key to GitHub!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34780631-0e07-498b-8ccf-337451cb8ea0",
   "metadata": {},
   "source": [
    "### AssistantAgent Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d708969c-6210-422f-9876-cf44de9977f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't be a fool and send your api key to GitHub!\n"
     ]
    }
   ],
   "source": [
    "# creating a Conversable Agent to accomlpish a simple task\n",
    "# 1st thing to do is to create a LLM config that specifies which LLM we want to use\n",
    "# model from the list of models provided by OpenAI https://platform.openai.com/docs/models/continuous-model-upgrades\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    # \"model\": \"gpt-3.5-turbo\",\n",
    "    \"api_key\": api_key\n",
    "    }\n",
    "print(\"Don't be a fool and send your api key to GitHub!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bab46ad-c2b1-413e-a8ff-42d0a2a66e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring a Conversable Agent that will NEVER ask for our input and will use the defined model to answer\n",
    "agent = ConversableAgent(\n",
    "    name=\"chatbot\",\n",
    "    llm_config=llm_config, # The Agent will use the LLM config provided to answer\n",
    "    human_input_mode=\"NEVER\", # Can also be ALWAYS or TERMINATE (at end only)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f1e9f7-c9c6-4549-a228-ca21ee1c071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen.agentchat.conversable_agent.ConversableAgent at 0x12cae36e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea31ac1-f00f-4fc1-be74-cdca211923f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A fun fact about money is that the first paper money was created in China during the Tang Dynasty, around the 7th century. However, it was during the Song Dynasty (11th century) that it became widely used. This paper currency was called \"jiaozi\" and was initially backed by precious metals, making it a revolutionary development in commerce and trade at the time!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's send a first request (= a prompt) to this agent\n",
    "# using the `generate_reply()` function of this agent\n",
    "# the message gets sent as a dictionary that must specify the `content` and the `role` keys\n",
    "# (we could actually send several messages in i√≥n request) \n",
    "# the `user` role means this is a request, we could use\n",
    "# the `system` role to specify a system prompt for this agent\n",
    "reply = agent.generate_reply(\n",
    "    messages=[\n",
    "        {\n",
    "            \"content\": \"Tell me a fun fact about money.\",\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2ec3325-84c8-4363-bfb2-2e935aed7c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fun fact about money is that the first paper money was created in China during the Tang Dynasty, around the 7th century. However, it was during the Song Dynasty (11th century) that it became widely used. This paper currency was called \"jiaozi\" and was initially backed by precious metals, making it a revolutionary development in commerce and trade at the time!\n"
     ]
    }
   ],
   "source": [
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da21de-3200-448c-8e4b-99fc47cec784",
   "metadata": {},
   "source": [
    "__Important to note point: when we use this `generate_reply()` function, we do not alter the state of this agent. This doesn't allow to have long conversations about a subject or solve tasks that require several steps. To explain what this means: if we try to ask this agent something that refers to this last query, we'll see that it has no idea what was this previous query.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61e5c4b-d744-4405-8aca-b42da2bf39a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Please provide the fact you'd like me to repeat.\n"
     ]
    }
   ],
   "source": [
    "reply = agent.generate_reply(\n",
    "    messages=[\n",
    "        {\n",
    "            \"content\": \"Repeat the fact.\", \n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c6d7b-86b9-4738-9ffc-50cec9be57c5",
   "metadata": {},
   "source": [
    "__To solve this we need to keep the state to be able to solve complex tasks. So we first need to be able to create conversations that alter the state of an agent if we want to solve complex tasks. An approach to achieve this is to create two agents that have evolving states based on their answers and that will converse based on these states.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7be7ea-6493-4004-814d-d1cb3eb656ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
