{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a716eed0-a06c-4fe5-8857-c4c2201b3fa3",
   "metadata": {},
   "source": [
    "# The Foundation: Markov Decision Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e7a91a-0a28-40b5-85ed-c616f546249b",
   "metadata": {},
   "source": [
    "Reinforcement Learning involves sequential decision making. Stochastic processes are used to model sequential decision-making behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eec52a-2954-4377-be1e-3179699cec69",
   "metadata": {},
   "source": [
    "## Definition of Reinforcement Learning (RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27e173-4bb1-419c-ad01-5db4df25fe97",
   "metadata": {},
   "source": [
    "__definition of Reinforcement Learning (RL) ...__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d8703-1fb6-48d7-8735-8db1a153bfc0",
   "metadata": {},
   "source": [
    "### Introducing Markov Chains (MC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579126f-c5b6-40d7-a0e7-7accf63e0ad9",
   "metadata": {},
   "source": [
    "### Introducing Markov Reward Processes (MRP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e99fa49-79d0-494c-8e9c-e83143b70290",
   "metadata": {},
   "source": [
    "## Markov Decision Processes in Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb071750-2ea4-426c-9f71-581119ebb483",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ccec90-0bec-498b-9195-337f7097b1e8",
   "metadata": {},
   "source": [
    "### Assumptions behind MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd5617-9c48-49e4-bbf9-9be7412a4e03",
   "metadata": {},
   "source": [
    "### Related Concepts: value functions of state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693ed28b-d46e-4728-9262-4ad0c4d98a0e",
   "metadata": {},
   "source": [
    "### Related Concepts: action value functions of state-action pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14476b54-6444-4f4f-bdc0-43b3cfb7a2ac",
   "metadata": {},
   "source": [
    "### The various forms of Bellman Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70264f44-d5ad-442a-8ff5-70e10e64064c",
   "metadata": {},
   "source": [
    "### Bellman optimality equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87d5d22-46d9-4534-b57d-3d5ba7b5cabe",
   "metadata": {},
   "source": [
    "## Training a couple of agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0c3a78-1aed-4ba8-9a2d-7ed324617e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
