{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5807a6cf-b8d3-4f27-970a-6526a4557a36",
   "metadata": {},
   "source": [
    "## 2.1. Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044872c7-6a3e-428d-b5c3-c67262f2680f",
   "metadata": {},
   "source": [
    "*Studying and coding along with the printed book __„Dive into Deep Learning“__ by Aston Zhang, Zachary C. Lipton, Mu Li & Alexander J. Smola. The accompanying website for the chapter Preliminaries > Data Manipulation can be found at [d2l.ai](https://d2l.ai/chapter_preliminaries/ndarray.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412ed0a0-5826-4078-8c83-3099d417ec9f",
   "metadata": {},
   "source": [
    "### 2.1.1. Getting started with Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b231a424-b6d4-4990-bab3-6a5de9dba073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the PyTorch library\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c916a9ee-78ca-4515-bbb6-37b9b7424423",
   "metadata": {},
   "source": [
    "#### __What is a tensor?__\n",
    "\n",
    "A tensor represents a (possibly multidimensional) array of numerical values. \n",
    "\n",
    "- In the one-dimensional case (only one axis is needed for the data) a tensor is called a **vector**.\n",
    "- With two axes, a tensor is called a **matrix**.\n",
    "- With *k > 2* axes, we drop the specialized names and just refer to the object as a ***k<sup>th</sup>*-order tensor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef978ab7-980c-40c7-a570-b1650de735ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating new tensors prepopulated with values with arange(n)\n",
    "# creates a vector of evenly spaced values\n",
    "# it starts at 0 (included) and ends at n (not included). \n",
    "# by default the interval size is 1\n",
    "# by default new tensors are stored in main memory and designated for CPU-based computation\n",
    "x = torch.arange(12, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "149137a2-69c1-485e-9984-be726ea93e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element of the tensor\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79033f0f-2a11-4d01-af7a-3edefaa321e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of elements in a tensor\n",
    "x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd2e53f6-3b20-4630-b43a-19e7ad874cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing a tensor’s shape (the length along each axis) by inspecting its shape attribute\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7e672d-9f15-4b77-ae50-85a7e61468a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the shape of a tensor without altering its size or values by invoking reshape\n",
    "# transform vector x to a matrix X with shape (3, 4)\n",
    "# the elements of the vector are laid out one row at a time: x[3] == X[0, 3]\n",
    "X = x.reshape(3,4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26d296b7-1582-4417-86dc-c6af0b8843e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daa6ec1b-f0d6-488b-bd2e-f57b4dcfe466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49166035-4102-4fff-a7d9-ab6a587e5bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7155a3-8603-4e26-befb-b7515bc2dcf9",
   "metadata": {},
   "source": [
    "If we know the size of a tensor size we can work out one component of the shape with the information we have:\n",
    "- Given a tensor of size *n* and target shape *(h, w)* we know that *w = n/h*.\n",
    "- Above example: given a tensor of 12 and target shape (3, w) we know that w = 12/3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd792669-3a0d-4dd0-89f7-8476e7bdb0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to automatically infer one component of the shape, we can place a -1 for the shape component that should be inferred automatically \n",
    "Y = x.reshape(-1, 4)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb632b96-e801-4acb-ba41-58f5818928e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = x.reshape(3, -1)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a3e6d0-b22d-4cd1-b378-6119f509b739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: a tensor initialized to contain all 0s or 1s\n",
    "# constructing a tensor with all elements set to 0 and a shape of (2, 3, 4)\n",
    "torch.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99946214-d1c9-4467-bce9-303da2b7be7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f79d9-67bf-456b-973a-b9d3ad723d47",
   "metadata": {},
   "source": [
    "#### __Sampling elements randomly from a given probability distribution__\n",
    "\n",
    "- It can be of advantage to sample each element randomly (and independently) from a given probability distribution. \n",
    "- For example, the parameters of neural networks are often initialized randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d2fe0a3-d229-43bf-98e6-533a4b16c784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9222, -1.5476, -0.1417,  0.3862],\n",
       "        [-0.7484,  0.2839,  0.9433,  0.3648],\n",
       "        [-1.3590,  0.9054,  0.2028, -1.1231]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor with elements drawn from a standard Gaussian (normal) distribution with mean 0 and standard deviation 1\n",
    "torch.randn(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c803839-a3be-473e-ad58-4194344f05f1",
   "metadata": {},
   "source": [
    "### 2.1.2. Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d782e65d-d97a-4cd1-b822-61713da589c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor elements cab be accessed by indexing, starting with 0\n",
    "# a whole ranges of indices can be accessed via slicing (e.g., X[start:stop]), \n",
    "## where the returned value includes the first index (start) but not the last (stop)\n",
    "X[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bff47b-b8d8-4fa4-80aa-a9b470956802",
   "metadata": {},
   "source": [
    "When only one index (or slice) is specified for a *k<sup>th</sup>*-order tensor, it is applied along axis 0.<br/>\n",
    "Thus, in the previous code, [-1] selects the last row and [1:3] selects the second and third rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcfd03d-2662-48a1-ace8-11e8a5a6d5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to access an element based on its position relative to the end of the list, we can use negative indexing\n",
    "X[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440ccc5-bcfd-477c-8105-2b58602d495c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4bfc001-1db1-4b40-87cf-de55f3783ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5., 17.,  7.],\n",
       "        [ 8.,  9., 10., 33.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writing elements of a matrix by specifying indices\n",
    "print(X)\n",
    "X[1, 2] = 17\n",
    "X[2, 3] = 33\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bdc620-7d77-4ea3-8dab-e31eb3591e33",
   "metadata": {},
   "source": [
    "#### __Assigning multiple elements the same value__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dca8c073-02e1-4a5e-a575-1eddd3fb684e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12., 12., 12.],\n",
       "        [12., 12., 12., 12.],\n",
       "        [ 8.,  9., 10., 33.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#, we apply the indexing on the left-hand side of the assignment operation\n",
    "# for instance, [:2, :] accesses the first and second rows\n",
    "## where : takes all the elements along axis 1 (column)\n",
    "X[:2, :] = 12\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35058323-0429-4c75-89d8-195e002151c9",
   "metadata": {},
   "source": [
    "### 2.1.3. Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca47a5-817e-4558-bbee-761eacdd2629",
   "metadata": {},
   "source": [
    "Manipulating tensors with various mathematical operations.\n",
    "\n",
    "__Elementwise operations__ apply a standard scalar operation to each element of a tensor. \n",
    "\n",
    "__Functions that take two tensors as inputs:__ Here elementwise operations apply some standard binary operator on each pair of corresponding elements. We can create an elementwise function from any function that maps from a scalar to a scalar.\n",
    "\n",
    "Mathematical notation (signature) for an elementwise function that maps from a scalar to a scalar (unary scalar operatorst): \n",
    "\n",
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>f</mi>\n",
    "  <mo>:</mo>\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mi mathvariant=\"double-struck\">R</mi>\n",
    "  </mrow>\n",
    "  <mo stretchy=\"false\">&#x2192;</mo>\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mi mathvariant=\"double-struck\">R</mi>\n",
    "  </mrow>\n",
    "</math>\n",
    "\n",
    "\n",
    "This just means that the function maps from any real number onto some other real number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84f3ea33-1250-4aed-a097-8811824274d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6275e+05, 1.6275e+05, 1.6275e+05, 1.6275e+05, 1.6275e+05, 1.6275e+05,\n",
       "        1.6275e+05, 1.6275e+05, 2.9810e+03, 8.1031e+03, 2.2026e+04, 2.1464e+14])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(x) # standard operators can be applied elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cb7eccf-bc20-4807-9232-e0dddb67ecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 4., 8.])\n",
      "tensor([2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2, 4, 8])\n",
    "y = torch.tensor([2, 2, 2, 2])\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3078003b-af02-4322-bdce-256d097d27f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.,  4.,  6., 10.]),\n",
       " tensor([-1.,  0.,  2.,  6.]),\n",
       " tensor([ 2.,  4.,  8., 16.]),\n",
       " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
       " tensor([ 1.,  4., 16., 64.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common standard arithmetic operators for addition (+), subtraction (-), multiplication (*), division (/)\n",
    "# and exponentiation (**) have all been lifted to elementwise operations for identically-shaped tensors of arbitrary shape\n",
    "x + y, x - y, x * y, x / y, x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830786cc-70dc-40e9-bd49-5f3345e4512d",
   "metadata": {},
   "source": [
    "#### __Concatenating Multiple Tensors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33d138c7-80a8-4bcd-926d-dd79eaa7249b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor X:\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.]])\n",
      "Tensor Y:\n",
      "tensor([[2., 1., 4., 3.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [4., 3., 2., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# concatenating multiple tensors by stacking them end-to-end to form a larger one\n",
    "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
    "print(\"Tensor X:\")\n",
    "print(X)\n",
    "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
    "print(\"Tensor Y:\")\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "865342c1-0f7c-4656-98ef-8035a1155543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y concatenated with dim=0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [ 2.,  1.,  4.,  3.],\n",
       "        [ 1.,  2.,  3.,  4.],\n",
       "        [ 4.,  3.,  2.,  1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# providing a list of tensors to the cat() function and tell the system along which axis to concatenate\n",
    "print(\"X and Y concatenated with dim=0:\")\n",
    "torch.cat((X, Y), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "146e3512-3b46-4f69-8c58-c075774ebd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X and Y concatenated with dim=1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
       "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"X and Y concatenated with dim=1:\")\n",
    "torch.cat((X, Y), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe1ff4-1cdb-42dd-8b9f-e0652118d9f1",
   "metadata": {},
   "source": [
    "#### __Constructing a binary tensor via logical statements__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11f57a09-fffb-4365-b0c1-eb60b4acd76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True, False,  True],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example: X == Y\n",
    "# for each position i, j, \n",
    "# if X[i, j] and Y[i, j] are equal -> the corresponding entry in the result takes value 1\n",
    "# if X[i, j] and Y[i, j] are not equal -> the corresponding entry in the result takes value 0\n",
    "X == Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5953c-6b73-4756-925a-48616e860542",
   "metadata": {},
   "source": [
    "#### __Summing all the elements in a tensor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0d2829c-5ce9-4dbb-8775-5bfae9ff58c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summing all the elements in the tensor yields a tensor with only one element\n",
    "X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32809f-2685-4951-8018-6dde9efb95e0",
   "metadata": {},
   "source": [
    "### 2.1.4. Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245ba53-2867-413f-9666-7a7a35772a80",
   "metadata": {},
   "source": [
    "Under certain conditions elementwise binary operations can be performed on tensors even when their shapes differ. This can be done by invoking the __broadcasting mechanism__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f112b8-eca0-476a-9bd3-142f840233a2",
   "metadata": {},
   "source": [
    "__The two-step procedure of broadcasting:__ \n",
    "\n",
    "1. Expand one or both arrays by copying elements along axes with length 1. After this transformation both tensors are supposed to have the same shape\n",
    "2. Perform an elementwise operation on the resulting arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "238443bf-9cfc-4dbe-98d8-eb8ca3c5e506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2]]),\n",
       " tensor([[0, 1]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(3).reshape((3, 1))\n",
    "b = torch.arange(2).reshape((1, 2))\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "442db291-e3aa-45f4-ba23-7218b2441d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Broadcasting: elementwise binary operations on tensors with different shapes\n",
    "# broadcasting produces a larger 3 x 2 matrix by replicating matrix a along the columns and matrix b along the rows \n",
    "# before adding them elementwise\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "deacfcac-35cb-44e7-a2d2-b2f1334086dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why are the added elements are 2 and 3 and not zeros?\n",
    "# Is it because the column of the first tensor gets copied into a second column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51f5b1-0802-4203-82d5-e015955beb2c",
   "metadata": {},
   "source": [
    "### 2.1.5. Saving Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa58ae63-344f-4984-be5f-c39728310c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4525695280"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python’s id() function gives us the exact address of the referenced object in memory\n",
    "id(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "722b3470-eee3-48f9-960c-ae22bfbfa4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4523262016"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = id(Y)\n",
    "# after a Y = X + Y operation the tensor that Y used to point gets dereferenced to \n",
    "# instead Y points at the newly allocated memory\n",
    "Y = Y + X\n",
    "# new memory for the result Y gets allocates; Y now points to this new location in memory\n",
    "id(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2776f797-bfc7-47bf-8eb6-fff82e56fd8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(Y) == before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48345011-f2e8-4999-aafa-e52867a33d5d",
   "metadata": {},
   "source": [
    "__Problems that might arise out of this:__\n",
    "1. Using an unecessary amount of memory: in machine learning we would allocate memory continiously if we update hundreds of megabytes of parameters multiple times per second.\n",
    "2. The same parameters might point to differnt locations of allocated memory. We would have to keep track of all these references and update them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1a02e-5986-418d-8bca-d54215824a80",
   "metadata": {},
   "source": [
    "__Solution: performing in-place operations__\n",
    "\n",
    "We can assign the result of an operation to a previously allocated place in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef6df1d7-1d60-4750-a85d-9f32677de6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "id(Z): 4532255856\n",
      "--------------------------------------\n",
      "Z:\n",
      "tensor([[ 2.,  4., 10., 12.],\n",
      "        [13., 17., 21., 25.],\n",
      "        [28., 30., 32., 34.]])\n",
      "id(Z): 4532255856\n"
     ]
    }
   ],
   "source": [
    "# initializing tensor Z using zeros_like to have the same shape as Y\n",
    "Z = torch.zeros_like(Y)\n",
    "print(\"Z:\")\n",
    "print(Z)\n",
    "\n",
    "print('id(Z):', id(Z))\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "# assigning the result of an operation to a previously allocated array Y by using slice notation: Y[:] = <expression>\n",
    "Z[:] = X + Y\n",
    "print(\"Z:\")\n",
    "print(Z)\n",
    "\n",
    "print('id(Z):', id(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6be8d06-e01d-4d2e-a031-6ff8b00dfb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(X): 4556468032\n",
      "id(X): 4556468032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in a similar way the += operator can be used\n",
    "before = id(X)\n",
    "print('id(X):', id(X))\n",
    "\n",
    "X += Y\n",
    "print('id(X):', id(X))\n",
    "\n",
    "id(X) == before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484d04c-17a5-43e7-8346-c397233063d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
