{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad29092-3405-4a2b-9a45-c0f490e36eb7",
   "metadata": {},
   "source": [
    "## 3.1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07482f64-d3ec-4239-967e-12ce82bd7786",
   "metadata": {},
   "source": [
    "*Studying and coding along with the printed book __„Dive into Deep Learning“__ by Aston Zhang, Zachary C. Lipton, Mu Li & Alexander J. Smola. The accompanying website for the chapter Linear Neural Networks for Regression > Linear Regression can be found at [d2l.ai](https://d2l.ai/chapter_linear-regression/linear-regression.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02232011-35f7-4c5b-9c4b-137c351a1e7a",
   "metadata": {},
   "source": [
    "__Solving a regression problem very much means predicting a numerical value.__\n",
    "\n",
    "Common examples:\n",
    "\n",
    "- Predicting prices of homes or stocks\n",
    "- Predicting the length of stays for patients in a hospital\n",
    "- Forecasting demand for retail sales\n",
    "\n",
    "There are also prediction problems that are classification problems with the goal of predicting membership among a set of categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be19d73-4940-4a12-8909-66ee405de7ff",
   "metadata": {},
   "source": [
    "__Let's use the following scenario as an example:__ we want to estimate the *prices of houses* (in US\\\\$) based on their *size/area* in square feet and their *age* in years. \n",
    "\n",
    "Our goal is to __develop a model for predicting house prices__.\n",
    "\n",
    "- The first step is to generate a *dataset* with sales prices, area and age for a number of homes.\n",
    "- This dataset will be our *training dataset* or ***training set***\n",
    "- Each row of the dataset is called an *example* (or *data point*, *instance*, *sample*).\n",
    "- An example contais the data corresponding to one sale.\n",
    "- What we're trying to predict is the sales price which in technical terminology is called a *label* (or ***target***).\n",
    "- Variables (in our case age and area) upon which the predictions are based are called ***features*** (or *covariates*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef86b73-5a25-4da1-83a1-e56bc4669a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d111e-8e63-4e98-84f5-cd18f35e4c3c",
   "metadata": {},
   "source": [
    "### 3.1.1. Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7d1d8e-1a90-43b4-8bee-62e2f58bdb3e",
   "metadata": {},
   "source": [
    "Some basic assumptions we make in *linear regression*:\n",
    "\n",
    "1. We assume that the relationship between features $\\mathbf{x}$ and target $y$ is approximately linear\n",
    "   - The conditional mean $E[Y \\mid X=\\mathbf{x}]$ can be expressed as a weighted sum of the features $\\mathbf{x}$\n",
    "   - The target value might deviate from its expected value on account of observation noise\n",
    "   - The assumption that any such noise is well behaved, following a Gaussian distribution\n",
    "2. $n$ will be used to denote the number of examples in our dataset\n",
    "   - Superscripts will be used to enumerate samples and targets: $\\mathbf{x}^{(i)}$ denotes the $i^{\\textrm{th}}$ sample\n",
    "   - Subscripts will be used to index coordinates: $x_j^{(i)}$ denotes its $j^{\\textrm{th}}$ coordinate\n",
    "\n",
    "*(These notes are taken form the printed book and the GitHup repo [d2l-ai/d2l-en](https://github.com/d2l-ai/d2l-en); mathematical notation is copied from the github repo as I still have to figure out how to write and read it correctly)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb8c59-2cba-4a5f-8578-f06a98cc963f",
   "metadata": {},
   "source": [
    "#### 3.1.1.1. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79d1f1c-5744-4b0a-837d-ba91503c90d3",
   "metadata": {},
   "source": [
    "The description of how features can be transformed into an estimate of the target is what we call a *model*.\n",
    "\n",
    "We assume the this transformation is linear. This assumption of linearity means that\n",
    "- the expected value of the *target* (price) can be expressed as a weighted sum of the *features* (area and age):\n",
    "  $$\\textrm{price} = w_{\\textrm{area}} \\cdot \\textrm{area} + w_{\\textrm{age}} \\cdot \\textrm{age} + b.$$\n",
    "\n",
    "- What we have here is an *affine transformation* of input features: a *linear transformation* of features via a weighted sum ***combined with a *translation* via the added bias***\n",
    "  \n",
    "- In this example $w_{\\textrm{area}}$ and $w_{\\textrm{age}}$ are the *weights* (***they determine the influence of each feature on our prediction***)\n",
    "- $b$ is what we call a *bias* (other terms for it are *offset* or *intercept*) (***it determines the value of the estimate when all features are zero***)\n",
    "  - the bias allows us to express all linear functions of our features\n",
    "\n",
    "***Our goal for a given sample is*** \n",
    "- to choose the weights $\\mathbf{w}$ and\n",
    "- to choose the bias $b$\n",
    "in a way that ***the predictions our model will make will fit the true prices observed as closely as possible***.\n",
    "\n",
    "***Linear algebra notation for high-dimensional datasets that are commonly used in machine learning:***\n",
    "$$\\hat{y} = w_1  x_1 + \\cdots + w_d  x_d + b$$\n",
    "\n",
    "- Given an input of $d$ features\n",
    "- each gets assigned an index (between $1$ and $d$)\n",
    "- and our prediction is denoted with the \"hat\" symbol: $\\hat{y}$\n",
    "\n",
    "All features are collected into a vector $\\mathbf{x} \\in \\mathbb{R}^d$ and all weights into a vector $\\mathbf{w} \\in \\mathbb{R}^d$. By doing this ***our model can be expressed via the dot product*** between $\\mathbf{w}$ and $\\mathbf{x}$:\n",
    "$$\\hat{y} = \\mathbf{w}^\\top \\mathbf{x} + b.$$\n",
    "In this equation the vector $\\mathbf{x}$ corresponds to the features of a single example.\n",
    "\n",
    "If we want to refer to features of our entire dataset of $n$ examples we use the *design matrix* $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ ($\\mathbf{X}$ contains one row for every example and one column for every feature).\n",
    "\n",
    "For a collection of features $\\mathbf{X}$, the predictions $\\hat{\\mathbf{y}} \\in \\mathbb{R}^n$ can be expressed via the \n",
    "\n",
    "The following matrix-vector product expresses \n",
    "- the predictions $\\hat{\\mathbf{y}} \\in \\mathbb{R}^n$\n",
    "- for a collection of features $\\mathbf{X}$\n",
    "\n",
    "$${\\hat{\\mathbf{y}}} = \\mathbf{X} \\mathbf{w} + b,$$\n",
    "\n",
    "*Broadcasting is applied during the summation of the features*.\n",
    "\n",
    "**Let's assume we've training dataset $\\mathbf{X}$ and corresponding labels $\\mathbf{y}$ which are known.**\n",
    "- The goal of linear regression now is to find the weight vector $\\mathbf{w}$ and the bias term $b$\n",
    "- in a way that for given features of a new data example sampled from the same distribution as $\\mathbf{X}$\n",
    "- this new dataset's labels will be predicted with the smallest error\n",
    "\n",
    "***It's important to be aware of that even when we are confident that the underlying relationship is linear, there might be a small amount of measurement error***\n",
    "- Therefor we will incorporate a noise term to account for such errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc465d-ec23-4b15-8851-ee3331e46e92",
   "metadata": {},
   "source": [
    "Two ***prerequisites*** we need to take into account are\n",
    "1. a measure of the quality of some given model\n",
    "2. a procedure for updating the model to improve its quality\n",
    "\n",
    "Once we have solved this, we can go and search for the best *model parameters* $\\mathbf{w}$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1726b468-91e0-447c-9ef6-3656fad8953f",
   "metadata": {},
   "source": [
    "### 3.1.2. Vectorization for Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6795989-5681-45bf-b955-ff2ccf7668a9",
   "metadata": {},
   "source": [
    "When training our models, we typically want to process whole minibatches of examples simultaneously. \n",
    "Doing this efficiently requires that we vectorize the calculations and leverage fast linear algebra libraries rather than writing costly for-loops in Python.\n",
    "\n",
    "To see why this matters so much, let’s consider two methods for adding vectors. To start, we instantiate two 10,000-dimensional vectors containing all 1s. In the first method, we loop over the vectors with a Python for-loop. In the second, we rely on a single call to +."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4863ca-33be-44f8-8ac2-66c9677d3e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "a = torch.ones(n)\n",
    "b = torch.ones(n)\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d2150-24a3-4dd3-91d5-8e3a7a978129",
   "metadata": {},
   "source": [
    "#### __Benchmarking the workloads__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfd0fd79-9c00-4b7f-8c9f-51a92af2381a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12503 sec'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding them using a for-loop, one coordinate at a time\n",
    "c = torch.zeros(n)\n",
    "t = time.time()\n",
    "for i in range(n):\n",
    "    c[i] = a[i] + b[i]\n",
    "f'{time.time() - t:.5f} sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a4883ba-1aa0-49cc-994e-782c428b9ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00100 sec'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizing code, pushing the mathematics to the library\n",
    "# computing the elementwise sum with the reloaded + operator\n",
    "t = time.time()\n",
    "d = a + b\n",
    "f'{time.time() - t:.5f} sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ce047-101d-44cd-8b50-7f40fe4089cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
