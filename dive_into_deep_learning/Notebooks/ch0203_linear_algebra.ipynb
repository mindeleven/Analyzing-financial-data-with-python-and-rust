{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2d9157-67df-4f47-8a44-2a3216ddaaa1",
   "metadata": {},
   "source": [
    "## 2.3. Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d2b66b-a7e0-44a5-a748-0ea85858c7ac",
   "metadata": {},
   "source": [
    "*Studying and coding along with the printed book __„Dive into Deep Learning“__ by Aston Zhang, Zachary C. Lipton, Mu Li & Alexander J. Smola. The accompanying website for the chapter Preliminaries > Linear Algebra can be found at [d2l.ai](https://d2l.ai/chapter_preliminaries/linear-algebra.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72527c6-19f8-40ac-beda-7ca47b85f562",
   "metadata": {},
   "source": [
    "__In order to build sophisticated models with tensors we will need some knowledge of linear algebra. *There's no way around it :)*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da9dd450-6789-4871-b387-d93644c2f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224e7bb-611e-45f8-adcb-a022a8e69127",
   "metadata": {},
   "source": [
    "### 2.3.1. Scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2ea71-f8b0-4e5d-80e1-eb71b8673f4e",
   "metadata": {},
   "source": [
    "- The values in mathematical operations are called __scalars__\n",
    "- Known values (like 5 or 9 in an equation) are __constant scalars__. Unknow variables (like c or f in an equation) represent __unknown scalars__\n",
    "- Scalars are denoted by lower case letters like x, y or z\n",
    "- The space of all (continuous) real-valued scalars is <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mi mathvariant=\"double-struck\">R</mi>\n",
    "  </mrow>\n",
    "</math>\n",
    "- <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>x</mi>\n",
    "  <mo>&#x2208;</mo>\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mi mathvariant=\"double-struck\">R</mi>\n",
    "  </mrow>\n",
    "</math> is a formal way to say that x is a real-valued scalar\n",
    "- The symbol <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mo>&#x2208;</mo>\n",
    "</math> (pronounced “in”) denotes membership in a set\n",
    "- <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>x</mi>\n",
    "  <mo>,</mo>\n",
    "  <mi>y</mi>\n",
    "  <mo>&#x2208;</mo>\n",
    "  <mo fence=\"false\" stretchy=\"false\">{</mo>\n",
    "  <mn>0</mn>\n",
    "  <mo>,</mo>\n",
    "  <mn>1</mn>\n",
    "  <mo fence=\"false\" stretchy=\"false\">}</mo>\n",
    "</math> for example, indicates that x and y are variables that can only take values 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "734a6009-b4ce-4cf7-a7a6-ba39e89d3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalars are implemented as tensors that contain only one element\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "33b72746-b998-411d-8af9-db7f592a9f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing the addition, multiplication, division, and exponentiation operations\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b46c50aa-7e21-43c3-92b5-8cd4602a685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b219908-311a-4823-811b-7d8147bb0b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00860094-7b71-41f5-a23b-4e8fcfb3ddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9f9f39ee-bb16-48e6-8b3f-aa08be0bcf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619fac78-a07b-4254-92b9-55221b8233d2",
   "metadata": {},
   "source": [
    "### 2.3.2. Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc946a-40e7-4f99-93f9-19ff238efc3e",
   "metadata": {},
   "source": [
    "- A vector as like a fixed-length array of scalars\n",
    "- These scalars are the elements of the vector (synonyms: entries or components)\n",
    "- As an example, studying the risk of heart attack: Each patient might get a vector assigned with the elements \"most recent vital signs\", \"cholesterol levels\" or \"minutes of exercise per day\"\n",
    "- In the book vectors are denoted by bold lowercase letters like **x**, **y** or **z**\n",
    "- Vectors are implemented as 1<sup>st</sup>-order tensors which can have arbitrary length\n",
    "- Python vector indices start at 0 (zero-based indexing)\n",
    "- In linear algebra subscripts begin at 1 (one-based indexing)\n",
    "- By default vectors are visualized by stacking their elements __vertically__\n",
    "- In general there are column vectors and row vectors whose elements are stacked horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89d16da1-6148-494a-9d0b-ce2be88edd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8754a6-dcf8-4a46-ab2b-9cd7d9a7995c",
   "metadata": {},
   "source": [
    "The elements of a vector can be denoted by using a subscript.\n",
    "\n",
    "<img src=\"../assets/images/0231_vector.png\" style=\"width:150px;vertical-align:middle\" />\n",
    "\n",
    "x<sub>2</sub> (a scalar), denotes the second element of vector **x**. (But we would access it in Python with x[1].)\n",
    "\n",
    "The vector contains n elements (n is the dimesionality of the vector): x ⋲ ℝ<sup>n</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76e11049-423f-4bf8-a593-f8d04592e7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acessing a tensors element via indexing\n",
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c0ada91-b26f-4446-b040-5adfed26204f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a tensor’s length is accessible via Python’s built-in len function\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2d96253-d330-471e-ac39-ee3b5f13665c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing the length via the shape attribute\n",
    "# it returns a tuple that indicates a tensor’s length along each axis\n",
    "# tensors with just one axis have shapes with just one element\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8f841-28c8-4c49-9ca0-d950cd8c0a7f",
   "metadata": {},
   "source": [
    "__Clarifying the use of the word “dimension”:__\n",
    "\n",
    "- “dimension” is often used to mean both, the number of axes and the length along a particular axis\n",
    "- in this book (or tutorial), <span style=\"color:red\">\n",
    "  - ***“order” is used to refer to the number of axes***\n",
    "  - ***dimensionality exclusively is used to refer to the number of components***</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dca3f9-e57e-4aec-a8ca-cd2d235cf710",
   "metadata": {},
   "source": [
    "### 2.3.3. Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa4d82-2bdb-4ee0-b898-101a00c0fcc0",
   "metadata": {},
   "source": [
    "- Scalars are 0<sup>th</sup>-order tensors\n",
    "- Vectors are 1<sup>st</sup>-order tensors\n",
    "- Matrices are 2<sup>nd</sup>-order tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b7460-aedc-49b1-a95a-9bc594f1fdce",
   "metadata": {},
   "source": [
    "- Matrices are denoted by bold capital letters (e.g., **X**, **Y** or **Z**)\n",
    "- In code the are reprsesentd by tensors with two axes\n",
    "- Matrices are often used for representing datasets with rows corresponding to individual records and columns corresponding to attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ffd558-574e-4f20-92e5-a62a7de41dc2",
   "metadata": {},
   "source": [
    "- A matrix **A** containing m * n real-valued scalars is expressed as **A** ⋲ ℝ<sup>m * n</sup>\n",
    "- The scalars are arranged as m rows and n columns\n",
    "- A matrix is *square* when m = n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df0ddc-bff0-4171-ab38-0a6e00c90957",
   "metadata": {},
   "source": [
    "Visual representation of a matrix as a table:\n",
    "\n",
    "<img src=\"../assets/images/0232_matrix.png\" style=\"width:300px;vertical-align:middle\" />\n",
    "\n",
    "Referring to an individal element: a <sub>ij</sub> is the value at **A**'s i<sup>th</sup> and j<sup>th</sup> column.\n",
    "\n",
    "In code a matrix **A** ⋲ ℝ<sup>m * n</sup> is represented by a 2<sup>nd</sup> order tensor with shape (m, n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a5dade45-6440-4e56-938b-412b0f6d3fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3,2)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd63af-9af1-4326-937e-6eabb90f970e",
   "metadata": {},
   "source": [
    "#### __Transpose___\n",
    "\n",
    "In linear algebra, the transpose of a matrix is an operator which flips a matrix over its diagonal; that is, it switches the row and column indices of the matrix **A*+ by producing another matrix, often denoted by **AT** (among other notations) (Source: https://en.wikipedia.org/wiki/Transpose).\n",
    "\n",
    "The transpose of a *m * n* matrix is a *n * m* matrix.\n",
    "\n",
    "A matrix **A**'s transpose is signifyd by **A<sup>T</sup>**. If **B** = **A<sup>T</sup>** then b<sub>ij</sub> = a<sub>ji</sub>.\n",
    "\n",
    "<img src=\"../assets/images/0233_matrix_transpose.png\" style=\"width:400px;vertical-align:middle\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbdb0fdf-0ad8-4df9-a2e1-19e0ad249565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing any matrix’s transpose\n",
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b7e26-6871-41f9-b2e9-6b34f7762fe2",
   "metadata": {},
   "source": [
    "Symmetric matrices are the subset of square matrices that are equal to their own transposes: **A** = **A<sup>T</sup>**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba7760f2-9490-452e-8288-2fa16617a9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of a symmetric matrix\n",
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "84a8a693-b6b3-46e9-8a98-fa71b5b86bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A == A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fdf872-958d-4b0b-bf86-47b54d93a37f",
   "metadata": {},
   "source": [
    "### 2.3.4. Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3171e9-8301-4965-8916-fe6f472bfb83",
   "metadata": {},
   "source": [
    "- Tensors allow it to describe extensions to n<sub>th</sub>-order arrays\n",
    "- Software objects of the tensor class can have an arbitrary numbers of axes\n",
    "- The word tensor for both the mathematical object and its realization in code (and therefore might be a bit confusing for the novice learner)\n",
    "- Tensors will become important when working with images\n",
    "- Each image arrives as a 3<sub>rd</sub>-order tensor with axes corresponding to the height, width, and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f48dccf-5081-441f-874d-b95dd68e80d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf896c37-b6d3-4552-aae0-294cc3615e41",
   "metadata": {},
   "source": [
    "### 2.3.5. Basic Properties of Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369873d8-abc2-4d89-9f08-b2ed79bf0a0b",
   "metadata": {},
   "source": [
    "Elementwise operations with scalars, vectors, matrices and higher-order tensors produce outputs that have the same shape as their operands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "197780fa-4c01-4dba-83f1-0045a763458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3) # 2x3 matrix\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0fcb865b-913e-418d-9c3e-941cce4f70c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A.clone() # cloning A and receiving another 2x3 matrix\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "296a9fdd-d1ea-4e55-9f69-59b4d2fcc322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  2.,  4.],\n",
       "        [ 6.,  8., 10.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addition of two matrices\n",
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c423ab-d127-4de0-9af9-7971cab4df8c",
   "metadata": {},
   "source": [
    "The elementwise product of two matrices is called their __Hadamard product__ (⊙ symbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e7d7c6ec-83cf-475f-9ca1-6269c253ce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3b775-6025-40b1-b8a5-5bd609ff45c8",
   "metadata": {},
   "source": [
    "When adding a scalar to a tensor, the scalar is added to each element of the tensor. The resulting tensor has the same shape as the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b1aea8f-bd5d-487f-971b-1cc7ad69beb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9],\n",
       "         [10, 11, 12, 13]],\n",
       "\n",
       "        [[14, 15, 16, 17],\n",
       "         [18, 19, 20, 21],\n",
       "         [22, 23, 24, 25]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44880135-a661-4ddd-ba92-8001a9653279",
   "metadata": {},
   "source": [
    "When multiplying a scalar and a tensor, each element of the tensor is multiplied by the scalar. The resulting tensor has the same shape as the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5c03eb1-fa75-4aca-8575-669c41ab2d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   0,   66,  132,  198,  264,  330,  396,  462,  528,  594,  660],\n",
       "         [ 726,  792,  858,  924,  990, 1056, 1122, 1188, 1254, 1320, 1386],\n",
       "         [1452, 1518, 1584, 1650, 1716, 1782, 1848, 1914, 1980, 2046, 2112]],\n",
       "\n",
       "        [[2178, 2244, 2310, 2376, 2442, 2508, 2574, 2640, 2706, 2772, 2838],\n",
       "         [2904, 2970, 3036, 3102, 3168, 3234, 3300, 3366, 3432, 3498, 3564],\n",
       "         [3630, 3696, 3762, 3828, 3894, 3960, 4026, 4092, 4158, 4224, 4290]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 66\n",
    "Y = torch.arange(66).reshape(2, 3, 11)\n",
    "b * Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69a78d-b1a4-40d2-8daf-321641a36c7e",
   "metadata": {},
   "source": [
    "### 2.3.6. Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f3f74-e1e8-4afd-8069-bc4eeee0627b",
   "metadata": {},
   "source": [
    "Expressing the sum of the elements in a vector **x** of length *n*:\n",
    "\n",
    "<img src=\"../assets/images/sum_vec_x_n.png\" style=\"width:100px;vertical-align:middle\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "95d278c0-db36-40cf-9f56-9de07e359863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3bd198ee-e943-4a21-930a-0b26db243b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of the elements in a vector x\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da9b93-9182-4cd3-86e4-280b0d807768",
   "metadata": {},
   "source": [
    "Expressing sums over the elements of tensors of arbitrary shape by calculating the sums over all its axes. \n",
    "The sum of a *m * n* matrix **A**:\n",
    "\n",
    "<img src=\"../assets/images/sum_over_sum.png\" style=\"width:200px;vertical-align:middle\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6d268cf-fa8f-43fa-a5c6-54c2b588214b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3) # example from above\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "202866e7-347b-4770-80f4-ecf22d9c0c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7769d83-04f7-4063-bf4e-48b6350c6978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cab27232-b28d-48d9-9cb3-b6b5526efcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.])\n",
      "tensor([3., 4., 5.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(15.)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A[0])\n",
    "print(A[1])\n",
    "A[0].sum() + A[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c85af7-740f-4501-b34b-e69e4fe9976a",
   "metadata": {},
   "source": [
    "Invoking the sum function ***reduces a tensor along all of its axes and produces a scalar***. The `sum` function takes the axes along which the tensor should be reduced as an argument (axis=0 in sum means we sum over all elements along the rows).\n",
    "\n",
    "If we specify axis=0 in sum, the input matrix ***reduces along axis 0*** to generate the output vector. Therefore axis 0 is missing from the shape of the output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "24539a3f-04de-4ef8-aae7-1091fc11eefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "25a4bec1-5376-42ff-873b-747eeb15bc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 5., 7.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c485dff6-b673-409c-862b-5d783d51cd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8a71e85a-a9cc-4ed3-8602-21c26fc00838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3., 12.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passing axis=1 as a parameter will reduce the column dimension (axis 1)\n",
    "# this reduction will be done by summing up elements of all the columns\n",
    "A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cc7f633b-c1b7-4f96-b407-24e677573f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "66e639ba-1375-44c1-92f5-3a80f1609e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reducing a matrix along both rows and columns via summation\n",
    "# equivalent to summing up all the elements of the matrix\n",
    "A.sum(axis=[0,1]) == A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f3389-9e78-4159-b2ec-6ddc471f2310",
   "metadata": {},
   "source": [
    "__Calculating the mean of a tensor:__\n",
    "\n",
    "The mean (aka the average) is calculated by dividing the sum by the total number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1abdc5b2-0a8e-4499-bd75-bc4c0afea3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = A.sum() / A.numel()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1d6343c3-3cd1-46b9-ba61-12699d754227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dedicated library function that works analogously to sum\n",
    "A.mean() == mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ba89c7b1-682d-4106-b184-757bfe742794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 2.5000, 3.5000])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the mean by reducing a tensor along specific axes\n",
    "mean_axis_zero = A.sum(axis=0) / A.shape[0]\n",
    "mean_axis_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ab2306dd-0586-4836-9b0f-2aaeda49cc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0) == mean_axis_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92015aa8-6ded-472a-a761-f13ab2a21626",
   "metadata": {},
   "source": [
    "### 2.3.7. Non-Reduction Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70ed1b-ff7c-4260-bb3e-079bdac7ae3e",
   "metadata": {},
   "source": [
    "Keeping the number of axes unchanged when invoking the function for calculating the sum or mean, for example when we want to use the broadcast mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "86afec83-d7f6-4df7-924b-0cde3bd3527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7d5b423b-ee04-4322-9896-ed88104eaccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5ea00b97-b07f-4b2d-ad71-132f2b79be80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3., 12.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1) # sum over axis 1 regular style, doesn't keep shape\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "afb5c591-1701-4586-b4ee-fd0519774d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.],\n",
       "        [12.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True) # stays in shape with keepdims=True \n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d29f99e9-11bc-4187-adb1-956f49016ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9add4c7d-8c05-494b-97b8-44c2ec8efb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum_A keeps its two axes after summing each row\n",
    "# now lets divide A by sum_A with broadcasting to create a matrix where each row sums up to 1\n",
    "A / sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "49a5d34d-9450-4eeb-a93a-996b90e8923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the cumulative sum of elements of A axis=0 (row by row)\n",
    "# by calling the cumsum function\n",
    "# the cumsum function doesn't reduce the input tensor along any axis\n",
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cde4d17-4963-4644-8ade-da81e56532d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once again A for comparision's sake\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f41074e2-b034-4ce9-9426-04d720bca990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.arange(12).reshape(3,4)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c4df8b54-3946-4c11-9ccc-f4b4e14425a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  6,  8, 10],\n",
       "        [12, 15, 18, 21]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.cumsum(axis=0) # last row gets replaced with cumlulative sum of all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7f3a0e52-2b67-48f7-8885-003a394208ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.arange(12).reshape(3,4)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3b36195f-1761-4caf-a5e9-086c8c961263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  3,  6],\n",
       "        [ 4,  9, 15, 22],\n",
       "        [ 8, 17, 27, 38]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.cumsum(axis=1) # last column gets replaced with cumlulative sum of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733bdf3-82cc-4cad-8f73-47abf21b2dd5",
   "metadata": {},
   "source": [
    "### 2.3.8. Dot Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309d14c-10b0-4233-8e2f-e4c08df11d7d",
   "metadata": {},
   "source": [
    "- The dot product is one of the most fundamental operations in linear algebra\n",
    "- A dot product is a single number that reflects the commonalities between two objects (vectors, matrices, tensors, signals, images)\n",
    "- Given two products **x, y** ⋲ ℝ<sup>d</sup>, their dot product *x <sup>T</sup> y* ) is a sum over the products of the elements at the same position:\n",
    "\n",
    "<img src=\"../assets/images/0238_dot_product.png\" style=\"width:200px;vertical-align:middle\" />\n",
    "\n",
    "- The dot product is also know as inner product, (**x**, **y**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d9688d35-6afb-4f4e-ad1b-ef16b34e5c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf0911f1-05a5-4e62-b0bd-4cf93836cff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3, dtype = torch.float32)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8ca62647-8a32-4eaa-b707-380834e659c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cf285766-f218-4d0a-b414-c756e42af097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x * y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fb13b02-1746-4c50-b3a5-e13872d1d200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum() # is this how it's calculated?\n",
    "# first the product, then the sum over the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "09b552cd-fb9a-4bbe-866e-4271af9be080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the dot product of two vectors by performing an elementwise multiplication followed by a sum\n",
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27827018-1d1c-4d34-a419-c9d1db145297",
   "metadata": {},
   "source": [
    "__Now for some very abstract explanation of what can be done with the dot product:__\n",
    "\n",
    "- Let's say we have a vector **x** ⋲ ℝ<sup>n</sup> and a set of weights denoted by **w** ⋲ ℝ<sup>n</sup>\n",
    "- Now the weighted sum of the values in **x** according to the weights **w** could be expressed as the dot product **x**<sup>T</sup>**w**\n",
    "- When the weights are nonnegative and sum to 1, then the dot product expresses a weighted average\n",
    "- If we normalizing two vectors to have unit length, the dot products express the cosine of the angle between them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80bbdb2-6033-4c4e-8d15-caa249e1856b",
   "metadata": {},
   "source": [
    "### 2.3.9. Matrix–Vector Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de0358-c044-4e50-8c7c-773ec66507e1",
   "metadata": {},
   "source": [
    "Calculating the product between a *m x n* matrix **A*+ and a *n*-dimensional vector *x*. \n",
    "\n",
    "Beginning with a visualizing a matrix where each **a**<sub>*i*</sub><sup>T</sup> ⋲ ℝ<sup>n</sup> is a row vector \n",
    "representing the *i<sup>th</sup>* row of the matrix **A**:\n",
    "\n",
    "<img src=\"../assets/images/0239_matrix_vec_prod_1.png\" style=\"width:200px;vertical-align:middle\" />\n",
    "\n",
    "The matrix–vector product __Ax__is a column vector of length *m* whose *i<sup>th</sup>* element is the dot product **a**<sub>*i*</sub><sup>T</sup>:\n",
    "\n",
    "<img src=\"../assets/images/0239_matrix_vec_prod_2.png\" style=\"width:300px;vertical-align:middle\" />\n",
    "\n",
    "The multiplication with a matrix __A__ ⋲ ℝ<sup>*m*n*</sup> as a transformation that projects vectors from ℝ<sup>*n*</sup> to ℝ<sup>*m*</sup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "227b11f3-6bf2-4aa7-ba52-fcfb37588b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expressing a matrix–vector product in code\n",
    "# matrix A from above\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "87dc1b5e-6bc4-4673-80df-c04f3d3e559e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fc930950-9e11-43b3-9517-00cce1da4ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector x from above\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "88bbd6c7-f12b-4dc6-b476-1b7571594b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5532dd6d-8deb-4620-bd2f-80e163f20a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the column dimension of A (its length along axis 1) must be the same as the dimension of x (its length)\n",
    "A[1].shape == x.shape # is A[1].shape the length along axis 1 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b41d9e96-5935-49c1-b6d7-fb5ffcf677c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5., 14.])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the mv function to express a matrix–vector product in code\n",
    "torch.mv(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a6bab887-12fc-45ef-a85d-f8353a075776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5., 14.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# executing both matrix–vector product with operator @\n",
    "A@x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e36ea-2c11-461e-9786-7b16cec5670e",
   "metadata": {},
   "source": [
    "### 2.3.10. Matrix–Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f16126-eedc-4e65-b6c0-1aed66b99f08",
   "metadata": {},
   "source": [
    "We have two matrices, __A__ ⋲ ℝ<sup>*n*k*</sup> and __B__ ⋲ ℝ<sup>*k*m*</sup>:\n",
    "\n",
    "<img src=\"../assets/images/0239_matrix_matrix_prod_1.png\" style=\"width:80%;vertical-align:middle\" />\n",
    "\n",
    "- __a__<sub>*i*</sub><sup>T</sup> ⋲ ℝ<sup>*k*</sup> denotes the row vector representing the *i<sup>th</sup>* row of the matrix __A__\n",
    "- __b__<sub>*j*</sub> ⋲ ℝ<sup>*k*</sup> denotes the column vector representing the *j<sup>th</sup>* column of the matrix __B__\n",
    "\n",
    "<img src=\"../assets/images/0239_matrix_matrix_prod_2.png\" style=\"width:80%;vertical-align:middle\" />\n",
    "\n",
    "- To form the matrix product __C__ ⋲ ℝ<sup>*n*m*</sup> we compute each element *c<sub>ij</sub>* as the as the dot product between the *i<sup>th</sup>* row of __A__ and the *j<sup>th</sup>* column of __B__:\n",
    "\n",
    "<img src=\"../assets/images/0239_matrix_matrix_prod_3.png\" style=\"width:80%;vertical-align:middle\" />\n",
    "\n",
    "(The screenshots with mathematical notation are taken from [d2l.ai](https://d2l.ai/chapter_preliminaries/linear-algebra.html) because I really don't know how to write them in markdown.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf35fd0-626f-4598-bdf6-86419d843ce1",
   "metadata": {},
   "source": [
    "The matrix–matrix multiplication __AB__ can be seen as performing *m* matrix–vector products or *m*n* dot products and stitching the results together to form an *n*m* matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7ddc7e17-57ce-49f5-a09a-19656eceb794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code example for performing matrix multiplication on A and B\n",
    "# we already have A, a matrix with two rows and three columns\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "14bb4ab8-99b9-4421-a026-a98bd6b4555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create another matrix B\n",
    "# B is a matrix with three rows and four columns\n",
    "B = torch.ones(3, 4)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2c13df9f-e317-4775-8af2-3754f7464609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.,  3.,  3.],\n",
       "        [12., 12., 12., 12.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the mm function to express a matrix–matrix product in code\n",
    "# after multiplication, we obtain a matrix with two rows and four columns\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9da36f66-3e10-40b6-8517-9b4b7082e331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  3.,  3.,  3.],\n",
       "        [12., 12., 12., 12.]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same with the @ operator\n",
    "A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afce35b1-a05b-4f6a-b75b-98657395ec6c",
   "metadata": {},
   "source": [
    "- The term matrix–matrix multiplication is often simplified to matrix multiplication\n",
    "- Matrix multiplication should not be confused with the Hadamard product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcadc8a-f1b7-417f-95cf-ef7b9be0cd03",
   "metadata": {},
   "source": [
    "### 2.3.11. Norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ddce82-aa88-4d44-9c86-069c2e0ee34c",
   "metadata": {},
   "source": [
    "- The norm of a vector tells us how big the vector is\n",
    "- The $\\ell_2$ norm measures the (Euclidean) length of a vector\n",
    "- Size in this context concerns the magnitude of a vector’s components, not its dimensionality\n",
    "\n",
    "A norm is a function $\\| \\cdot \\|$ that maps a vector\n",
    "to a scalar and satisfies the following three properties:\n",
    "\n",
    "1. Given any vector $\\mathbf{x}$, if we scale (all elements of) the vector \n",
    "   by a scalar $\\alpha \\in \\mathbb{R}$, its norm scales accordingly:\n",
    "   $$\\|\\alpha \\mathbf{x}\\| = |\\alpha| \\|\\mathbf{x}\\|.$$\n",
    "2. For any vectors $\\mathbf{x}$ and $\\mathbf{y}$:\n",
    "   norms satisfy the triangle inequality:\n",
    "   $$\\|\\mathbf{x} + \\mathbf{y}\\| \\leq \\|\\mathbf{x}\\| + \\|\\mathbf{y}\\|.$$\n",
    "3. The norm of a vector is nonnegative and it only vanishes if the vector is zero:\n",
    "   $$\\|\\mathbf{x}\\| > 0 \\textrm{ for all } \\mathbf{x} \\neq 0.$$\n",
    "\n",
    "Many functions are valid norms and different norms \n",
    "encode different notions of size. \n",
    "The Euclidean norm that we all learned in elementary school geometry\n",
    "when calculating the hypotenuse of a right triangle\n",
    "is the square root of the sum of squares of a vector's elements.\n",
    "Formally, this is called [**the $\\ell_2$ *norm***] and expressed as\n",
    "\n",
    "(**$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}.$$**)\n",
    "\n",
    "(Source incl. mathematical notation: [D2L.ai: Interactive Deep Learning Book with Multi-Framework Code, Math, and Discussions](https://github.com/d2l-ai/d2l-en/blob/master/chapter_preliminaries/linear-algebra.md))\n",
    "\n",
    "In Python the method `norm` calculates 𝓁<sub>2</sub> the norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8ca790d9-70ae-42f6-95e3-f28fbc79b2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523e37f-6cd4-4c5d-98ec-8b8ae9235ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
