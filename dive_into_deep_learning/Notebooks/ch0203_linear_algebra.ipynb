{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2d9157-67df-4f47-8a44-2a3216ddaaa1",
   "metadata": {},
   "source": [
    "## 2.3. Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d2b66b-a7e0-44a5-a748-0ea85858c7ac",
   "metadata": {},
   "source": [
    "*Studying and coding along with the printed book __„Dive into Deep Learning“__ by Aston Zhang, Zachary C. Lipton, Mu Li & Alexander J. Smola. The accompanying website for the chapter Preliminaries > Linear Algebra can be found at [d2l.ai](https://d2l.ai/chapter_preliminaries/linear-algebra.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72527c6-19f8-40ac-beda-7ca47b85f562",
   "metadata": {},
   "source": [
    "__In order to build sophisticated models with tensors we will need some knowledge of linear algebra. *There's no way around it :)*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9dd450-6789-4871-b387-d93644c2f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224e7bb-611e-45f8-adcb-a022a8e69127",
   "metadata": {},
   "source": [
    "### 2.3.1. Scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2ea71-f8b0-4e5d-80e1-eb71b8673f4e",
   "metadata": {},
   "source": [
    "- The values in mathematical operations are called __scalars__\n",
    "- Known values (like 5 or 9 in an equation) are __constant scalars__. Unknow variables (like c or f in an equation) represent __unknown scalars__\n",
    "- Scalars are denoted by lower case letters like x, y or z\n",
    "- The space of all (continuous) real-valued scalars is <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mi mathvariant=\"double-struck\">R</mi>\n",
    "  </mrow>\n",
    "</math>\n",
    "- <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>x</mi>\n",
    "  <mo>&#x2208;</mo>\n",
    "  <mrow data-mjx-texclass=\"ORD\">\n",
    "    <mi mathvariant=\"double-struck\">R</mi>\n",
    "  </mrow>\n",
    "</math> is a formal way to say that x is a real-valued scalar\n",
    "- The symbol <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mo>&#x2208;</mo>\n",
    "</math> (pronounced “in”) denotes membership in a set\n",
    "- <math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n",
    "  <mi>x</mi>\n",
    "  <mo>,</mo>\n",
    "  <mi>y</mi>\n",
    "  <mo>&#x2208;</mo>\n",
    "  <mo fence=\"false\" stretchy=\"false\">{</mo>\n",
    "  <mn>0</mn>\n",
    "  <mo>,</mo>\n",
    "  <mn>1</mn>\n",
    "  <mo fence=\"false\" stretchy=\"false\">}</mo>\n",
    "</math> for example, indicates that x and y are variables that can only take values 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734a6009-b4ce-4cf7-a7a6-ba39e89d3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalars are implemented as tensors that contain only one element\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b72746-b998-411d-8af9-db7f592a9f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performing the addition, multiplication, division, and exponentiation operations\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46c50aa-7e21-43c3-92b5-8cd4602a685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b219908-311a-4823-811b-7d8147bb0b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00860094-7b71-41f5-a23b-4e8fcfb3ddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f9f39ee-bb16-48e6-8b3f-aa08be0bcf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x ** y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619fac78-a07b-4254-92b9-55221b8233d2",
   "metadata": {},
   "source": [
    "### 2.3.2. Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc946a-40e7-4f99-93f9-19ff238efc3e",
   "metadata": {},
   "source": [
    "- A vector as like a fixed-length array of scalars\n",
    "- These scalars are the elements of the vector (synonyms: entries or components)\n",
    "- As an example, studying the risk of heart attack: Each patient might get a vector assigned with the elements \"most recent vital signs\", \"cholesterol levels\" or \"minutes of exercise per day\"\n",
    "- In the book vectors are denoted by bold lowercase letters like **x**, **y** or **z**\n",
    "- Vectors are implemented as 1<sup>st</sup>-order tensors which can have arbitrary length\n",
    "- Python vector indices start at 0 (zero-based indexing)\n",
    "- In linear algebra subscripts begin at 1 (one-based indexing)\n",
    "- By default vectors are visualized by stacking their elements __vertically__\n",
    "- In general there are column vectors and row vectors whose elements are stacked horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d16da1-6148-494a-9d0b-ce2be88edd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8754a6-dcf8-4a46-ab2b-9cd7d9a7995c",
   "metadata": {},
   "source": [
    "The elements of a vector can be denoted by using a subscript.\n",
    "\n",
    "<img src=\"../assets/images/0231_vector.png\" style=\"width:150px;vertical-align:middle\" />\n",
    "\n",
    "x<sub>2</sub> (a scalar), denotes the second element of vector **x**. (But we would access it in Python with x[1].)\n",
    "\n",
    "The vector contains n elements (n is the dimesionality of the vector): x ⋲ ℝ<sup>n</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e11049-423f-4bf8-a593-f8d04592e7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acessing a tensors element via indexing\n",
    "x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c0ada91-b26f-4446-b040-5adfed26204f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a tensor’s length is accessible via Python’s built-in len function\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d96253-d330-471e-ac39-ee3b5f13665c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing the length via the shape attribute\n",
    "# it returns a tuple that indicates a tensor’s length along each axis\n",
    "# tensors with just one axis have shapes with just one element\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8f841-28c8-4c49-9ca0-d950cd8c0a7f",
   "metadata": {},
   "source": [
    "__Clarifying the use of the word “dimension”:__\n",
    "\n",
    "- “dimension” is often used to mean both, the number of axes and the length along a particular axis\n",
    "- in this book (or tutorial), <span style=\"color:red\">\n",
    "  - ***“order” is used to refer to the number of axes***\n",
    "  - ***dimensionality exclusively is used to refer to the number of components***</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dca3f9-e57e-4aec-a8ca-cd2d235cf710",
   "metadata": {},
   "source": [
    "### 2.3.3. Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa4d82-2bdb-4ee0-b898-101a00c0fcc0",
   "metadata": {},
   "source": [
    "- Scalars are 0<sup>th</sup>-order tensors\n",
    "- Vectors are 1<sup>st</sup>-order tensors\n",
    "- Matrices are 2<sup>nd</sup>-order tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b7460-aedc-49b1-a95a-9bc594f1fdce",
   "metadata": {},
   "source": [
    "- Matrices are denoted by bold capital letters (e.g., **X**, **Y** or **Z**)\n",
    "- In code the are reprsesentd by tensors with two axes\n",
    "- Matrices are often used for representing datasets with rows corresponding to individual records and columns corresponding to attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ffd558-574e-4f20-92e5-a62a7de41dc2",
   "metadata": {},
   "source": [
    "- A matrix **A** containing m * n real-valued scalars is expressed as **A** ⋲ ℝ<sup>m * n</sup>\n",
    "- The scalars are arranged as m rows and n columns\n",
    "- A matrix is *square* when m = n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df0ddc-bff0-4171-ab38-0a6e00c90957",
   "metadata": {},
   "source": [
    "Visual representation of a matrix as a table:\n",
    "\n",
    "<img src=\"../assets/images/0232_matrix.png\" style=\"width:300px;vertical-align:middle\" />\n",
    "\n",
    "Referring to an individal element: a <sub>ij</sub> is the value at **A**'s i<sup>th</sup> and j<sup>th</sup> column.\n",
    "\n",
    "In code a matrix **A** ⋲ ℝ<sup>m * n</sup> is represented by a 2<sup>nd</sup> order tensor with shape (m, n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5dade45-6440-4e56-938b-412b0f6d3fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6).reshape(3,2)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd63af-9af1-4326-937e-6eabb90f970e",
   "metadata": {},
   "source": [
    "#### __Transpose___\n",
    "\n",
    "In linear algebra, the transpose of a matrix is an operator which flips a matrix over its diagonal; that is, it switches the row and column indices of the matrix **A*+ by producing another matrix, often denoted by **AT** (among other notations) (Source: https://en.wikipedia.org/wiki/Transpose).\n",
    "\n",
    "The transpose of a *m * n* matrix is a *n * m* matrix.\n",
    "\n",
    "A matrix **A**'s transpose is signifyd by **A<sup>T</sup>**. If **B** = **A<sup>T</sup>** then b<sub>ij</sub> = a<sub>ji</sub>.\n",
    "\n",
    "<img src=\"../assets/images/0233_matrix_transpose.png\" style=\"width:400px;vertical-align:middle\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbdb0fdf-0ad8-4df9-a2e1-19e0ad249565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 2, 4],\n",
       "        [1, 3, 5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing any matrix’s transpose\n",
    "A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b7e26-6871-41f9-b2e9-6b34f7762fe2",
   "metadata": {},
   "source": [
    "Symmetric matrices are the subset of square matrices that are equal to their own transposes: **A** = **A<sup>T</sup>**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba7760f2-9490-452e-8288-2fa16617a9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [2, 0, 4],\n",
       "        [3, 4, 5]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of a symmetric matrix\n",
    "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84a8a693-b6b3-46e9-8a98-fa71b5b86bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A == A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fdf872-958d-4b0b-bf86-47b54d93a37f",
   "metadata": {},
   "source": [
    "### 2.3.4. Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3171e9-8301-4965-8916-fe6f472bfb83",
   "metadata": {},
   "source": [
    "- Tensors allow it to describe extensions to n<sub>th</sub>-order arrays\n",
    "- Software objects of the tensor class can have an arbitrary numbers of axes\n",
    "- The word tensor for both the mathematical object and its realization in code (and therefore might be a bit confusing for the novice learner)\n",
    "- Tensors will become important when working with images\n",
    "- Each image arrives as a 3<sub>rd</sub>-order tensor with axes corresponding to the height, width, and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f48dccf-5081-441f-874d-b95dd68e80d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(24).reshape(2, 3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf896c37-b6d3-4552-aae0-294cc3615e41",
   "metadata": {},
   "source": [
    "### 2.3.5. Basic Properties of Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369873d8-abc2-4d89-9f08-b2ed79bf0a0b",
   "metadata": {},
   "source": [
    "Elementwise operations with scalars, vectors, matrices and higher-order tensors produce outputs that have the same shape as their operands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "197780fa-4c01-4dba-83f1-0045a763458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3) # 2x3 matrix\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fcb865b-913e-418d-9c3e-941cce4f70c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A.clone() # cloning A and receiving another 2x3 matrix\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "296a9fdd-d1ea-4e55-9f69-59b4d2fcc322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  2.,  4.],\n",
       "        [ 6.,  8., 10.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addition of two matrices\n",
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c423ab-d127-4de0-9af9-7971cab4df8c",
   "metadata": {},
   "source": [
    "The elementwise product of two matrices is called their __Hadamard product__ (⊙ symbol)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d7c6ec-83cf-475f-9ca1-6269c253ce44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  4.],\n",
       "        [ 9., 16., 25.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e3b775-6025-40b1-b8a5-5bd609ff45c8",
   "metadata": {},
   "source": [
    "When adding a scalar to a tensor, the scalar is added to each element of the tensor. The resulting tensor has the same shape as the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b1aea8f-bd5d-487f-971b-1cc7ad69beb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9],\n",
       "         [10, 11, 12, 13]],\n",
       "\n",
       "        [[14, 15, 16, 17],\n",
       "         [18, 19, 20, 21],\n",
       "         [22, 23, 24, 25]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "a + X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44880135-a661-4ddd-ba92-8001a9653279",
   "metadata": {},
   "source": [
    "When multiplying a scalar and a tensor, each element of the tensor is multiplied by the scalar. The resulting tensor has the same shape as the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5c03eb1-fa75-4aca-8575-669c41ab2d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[   0,   66,  132,  198,  264,  330,  396,  462,  528,  594,  660],\n",
       "         [ 726,  792,  858,  924,  990, 1056, 1122, 1188, 1254, 1320, 1386],\n",
       "         [1452, 1518, 1584, 1650, 1716, 1782, 1848, 1914, 1980, 2046, 2112]],\n",
       "\n",
       "        [[2178, 2244, 2310, 2376, 2442, 2508, 2574, 2640, 2706, 2772, 2838],\n",
       "         [2904, 2970, 3036, 3102, 3168, 3234, 3300, 3366, 3432, 3498, 3564],\n",
       "         [3630, 3696, 3762, 3828, 3894, 3960, 4026, 4092, 4158, 4224, 4290]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 66\n",
    "Y = torch.arange(66).reshape(2, 3, 11)\n",
    "b * Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69a78d-b1a4-40d2-8daf-321641a36c7e",
   "metadata": {},
   "source": [
    "### 2.3.6. Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f3f74-e1e8-4afd-8069-bc4eeee0627b",
   "metadata": {},
   "source": [
    "Expressing the sum of the elements in a vector **x** of length *n*:\n",
    "\n",
    "<img src=\"../assets/images/sum_vec_x_n.png\" style=\"width:100px;vertical-align:middle\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95d278c0-db36-40cf-9f56-9de07e359863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bd198ee-e943-4a21-930a-0b26db243b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of the elements in a vector x\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da9b93-9182-4cd3-86e4-280b0d807768",
   "metadata": {},
   "source": [
    "Expressing sums over the elements of tensors of arbitrary shape by calculating the sums over all its axes. \n",
    "The sum of a *m * n* matrix **A**:\n",
    "\n",
    "<img src=\"../assets/images/sum_over_sum.png\" style=\"width:200px;vertical-align:middle\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6d268cf-fa8f-43fa-a5c6-54c2b588214b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6, dtype=torch.float32).reshape(2, 3) # example from above\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "202866e7-347b-4770-80f4-ecf22d9c0c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7769d83-04f7-4063-bf4e-48b6350c6978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(15.)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cab27232-b28d-48d9-9cb3-b6b5526efcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.])\n",
      "tensor([3., 4., 5.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(15.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A[0])\n",
    "print(A[1])\n",
    "A[0].sum() + A[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c85af7-740f-4501-b34b-e69e4fe9976a",
   "metadata": {},
   "source": [
    "Invoking the sum function ***reduces a tensor along all of its axes and produces a scalar***. The `sum` function takes the axes along which the tensor should be reduced as an argument (axis=0 in sum means we sum over all elements along the rows).\n",
    "\n",
    "If we specify axis=0 in sum, the input matrix ***reduces along axis 0*** to generate the output vector. Therefore axis 0 is missing from the shape of the output vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24539a3f-04de-4ef8-aae7-1091fc11eefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25a4bec1-5376-42ff-873b-747eeb15bc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 5., 7.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c485dff6-b673-409c-862b-5d783d51cd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a71e85a-a9cc-4ed3-8602-21c26fc00838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3., 12.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passing axis=1 as a parameter will reduce the column dimension (axis 1)\n",
    "# this reduction will be done by summing up elements of all the columns\n",
    "A.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc7f633b-c1b7-4f96-b407-24e677573f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66e639ba-1375-44c1-92f5-3a80f1609e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reducing a matrix along both rows and columns via summation\n",
    "# equivalent to summing up all the elements of the matrix\n",
    "A.sum(axis=[0,1]) == A.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f3389-9e78-4159-b2ec-6ddc471f2310",
   "metadata": {},
   "source": [
    "__Calculating the mean of a tensor:__\n",
    "\n",
    "The mean (aka the average) is calculated by dividing the sum by the total number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1abdc5b2-0a8e-4499-bd75-bc4c0afea3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = A.sum() / A.numel()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d6343c3-3cd1-46b9-ba61-12699d754227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dedicated library function that works analogously to sum\n",
    "A.mean() == mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ba89c7b1-682d-4106-b184-757bfe742794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5000, 2.5000, 3.5000])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the mean by reducing a tensor along specific axes\n",
    "mean_axis_zero = A.sum(axis=0) / A.shape[0]\n",
    "mean_axis_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab2306dd-0586-4836-9b0f-2aaeda49cc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.mean(axis=0) == mean_axis_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92015aa8-6ded-472a-a761-f13ab2a21626",
   "metadata": {},
   "source": [
    "### 2.3.7. Non-Reduction Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70ed1b-ff7c-4260-bb3e-079bdac7ae3e",
   "metadata": {},
   "source": [
    "Keeping the number of axes unchanged when invoking the function for calculating the sum or mean, for example when we want to use the broadcast mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "86afec83-d7f6-4df7-924b-0cde3bd3527b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d5b423b-ee04-4322-9896-ed88104eaccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5ea00b97-b07f-4b2d-ad71-132f2b79be80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3., 12.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1) # sum over axis 1 regular style, doesn't keep shape\n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "afb5c591-1701-4586-b4ee-fd0519774d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.],\n",
       "        [12.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1, keepdims=True) # stays in shape with keepdims=True \n",
    "sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d29f99e9-11bc-4187-adb1-956f49016ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9add4c7d-8c05-494b-97b8-44c2ec8efb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.3333, 0.6667],\n",
       "        [0.2500, 0.3333, 0.4167]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum_A keeps its two axes after summing each row\n",
    "# now lets divide A by sum_A with broadcasting to create a matrix where each row sums up to 1\n",
    "A / sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49a5d34d-9450-4eeb-a93a-996b90e8923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 5., 7.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the cumulative sum of elements of A axis=0 (row by row)\n",
    "# by calling the cumsum function\n",
    "# the cumsum function doesn't reduce the input tensor along any axis\n",
    "A.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8cde4d17-4963-4644-8ade-da81e56532d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# once again A for comparision's sake\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f41074e2-b034-4ce9-9426-04d720bca990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = torch.arange(12).reshape(3,4)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c4df8b54-3946-4c11-9ccc-f4b4e14425a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  6,  8, 10],\n",
       "        [12, 15, 18, 21]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B.cumsum(axis=0) # last row gets replaced with cumlulative sum of all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f3a0e52-2b67-48f7-8885-003a394208ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.arange(12).reshape(3,4)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b36195f-1761-4caf-a5e9-086c8c961263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  3,  6],\n",
       "        [ 4,  9, 15, 22],\n",
       "        [ 8, 17, 27, 38]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.cumsum(axis=1) # last column gets replaced with cumlulative sum of all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733bdf3-82cc-4cad-8f73-47abf21b2dd5",
   "metadata": {},
   "source": [
    "### 2.3.8. Dot Products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309d14c-10b0-4233-8e2f-e4c08df11d7d",
   "metadata": {},
   "source": [
    "- The dot product is one of the most fundamental operations in linear algebra\n",
    "- Given two products **x, y** ⋲ ℝ<sup>d</sup>, their dot product *x <sup>T</sup> y* ) is a sum over the products of the elements at the same position:\n",
    "\n",
    "<img src=\"../assets/images/0238_dot_product.png\" style=\"width:200px;vertical-align:middle\" />\n",
    "\n",
    "- The dot product is also know as inner product, (**x**, **y**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9688d35-6afb-4f4e-ad1b-ef16b34e5c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cf0911f1-05a5-4e62-b0bd-4cf93836cff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(3, dtype = torch.float32)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ca62647-8a32-4eaa-b707-380834e659c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf285766-f218-4d0a-b414-c756e42af097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x * y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0fb13b02-1746-4c50-b3a5-e13872d1d200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.sum() # is this how it's calculated?\n",
    "# first the product, then the sum over the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "09b552cd-fb9a-4bbe-866e-4271af9be080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the dot product of two vectors by performing an elementwise multiplication followed by a sum\n",
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27827018-1d1c-4d34-a419-c9d1db145297",
   "metadata": {},
   "source": [
    "__Now for some very abstract explanation of what can be done with the dot product:__\n",
    "\n",
    "- Let's say we have a vector **x** ⋲ ℝ<sup>n</sup> and a set of weights denoted by **w** ⋲ ℝ<sup>n</sup>\n",
    "- Now the weighted sum of the values in **x** according to the weights **w** could be expressed as the dot product **x**<sup>T</sup>**w**\n",
    "- When the weights are nonnegative and sum to 1, then the dot product expresses a weighted average\n",
    "- If we normalizing two vectors to have unit length, the dot products express the cosine of the angle between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd3c57-7066-42cd-a802-dde061664f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
